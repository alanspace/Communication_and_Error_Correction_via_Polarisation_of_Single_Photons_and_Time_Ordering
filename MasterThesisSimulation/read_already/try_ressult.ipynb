{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n = 1, time  = 0.1s\n",
    "<br> n= 2, time = 0.1s\n",
    "<br> n =3, time = 0.1s\n",
    "<br> n=4, time = 0.1s\n",
    "<br> n = 5, time = 0.1s  \n",
    "<br> n = 6, time = 0.1s\n",
    "<br> n= 7, time = 0.2s\n",
    "<br> n = 8, time = 0.2s\n",
    "<br> n= 9, time = 0.7s\n",
    "<br> n= 10, time =  6.6s\n",
    "<br> n= 11, time  = 1 min 17.3s\n",
    "<br> n = 12, time = 22 min 27.3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "from pyparsing import python_style_comment\n",
    "from itertools import islice\n",
    "import scipy.sparse as sps\n",
    "from scipy.sparse import diags\n",
    "from functools import lru_cache\n",
    "from multiprocessing import Pool\n",
    "from scipy.special import comb as combination"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n = 11, t = 1 min 17s\n",
    "n = 12, t = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_cache = {}\n",
    "#we need combination to calculate Loss_Disitribution, Add_Distribution, P_err\n",
    "# define a separate function for computing the sequence of terms used in N\n",
    "# def combination(n, r):\n",
    "#     # if r > n:\n",
    "#     #     return 0\n",
    "#     # else:\n",
    "#     return math.factorial((int(n))) / (math.factorial((int(n-r))) * math.factorial((int(r))))\n",
    "\n",
    "def combination(n, r):\n",
    "    if (n, r) in comb_cache:\n",
    "        return comb_cache[(n, r)]\n",
    "    else:\n",
    "        comb = math.factorial(n) // (math.factorial(n-r) * math.factorial(r))\n",
    "        comb_cache[(n, r)] = comb\n",
    "        return comb\n",
    "    \n",
    "@lru_cache(maxsize=None)\n",
    "def compute_N(n):\n",
    "  def agen(): # generator of terms\n",
    "      aset, sset, k = set(), set(), 0\n",
    "      while True:\n",
    "          k += 1\n",
    "          while any(k+an in sset for an in aset): k += 1\n",
    "          yield k; sset.update(k+an for an in aset); aset.add(k)\n",
    "  a = list(islice(agen(), 100))\n",
    "  photon = list(map(lambda v: v-1, a))\n",
    "  compute_N= [sum(photon[:i]) for i in range(1,len(photon)+1)]\n",
    "  return compute_N[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# We need LossDisitribution, AddDistribution, Perr to calculate PSuccess0, PSuccess1, PSuccess2 and so on\n",
    "# define a separate function for computing the loss distribution\n",
    "comb_n_cache = {}\n",
    "comb_n_M_minus_n_cache = {}\n",
    "# def Loss_Distribute(n, P_l, l):\n",
    "    # # if P_l == 0:\n",
    "    # #     return 1\n",
    "    # # else:\n",
    "    #   return combination(n, l) * (P_l)**l * (1 - P_l)**(n - l)\n",
    "\n",
    "def Loss_Distribute(n, P_l, l):\n",
    "    if (n, l) in comb_n_cache:\n",
    "        comb_n = comb_n_cache[(n, l)]\n",
    "    else:\n",
    "        comb_n = combination(n, l)\n",
    "        comb_n_cache[(n, l)] = comb_n\n",
    "\n",
    "    return comb_n * (P_l)**l * (1 - P_l)**(n - l)\n",
    "\n",
    "# def Add_Distribute(n, P_a, a):\n",
    "#     N_n = compute_N(n)\n",
    "#     # if P_a == 0:\n",
    "#     #     return 1\n",
    "#     # else:\n",
    "#     return combination(N_n - n, a) * (P_a)**a * (1 - P_a)**(N_n - n - a)\n",
    "\n",
    "def Add_Distribute(n, P_a, a):\n",
    "    N_n = compute_N(n)\n",
    "    M_minus_n = compute_N(n) - N_n\n",
    "    if (N_n, M_minus_n, a) in comb_n_M_minus_n_cache:\n",
    "        comb_Nn_Mn = comb_n_M_minus_n_cache[(N_n, M_minus_n, a)]\n",
    "    else:\n",
    "        comb_Nn_Mn = combination(N_n + M_minus_n, a)\n",
    "        comb_n_M_minus_n_cache[(N_n, M_minus_n, a)] = comb_Nn_Mn\n",
    "\n",
    "    return comb_Nn_Mn * (P_a)**a * (1 - P_a)**(M_minus_n - a)\n",
    "\n",
    "# define a separate function for computing the probability of error\n",
    "def P_err(n, P_l, P_a,l,a):\n",
    "  return Loss_Distribute(n,P_l,l) * Add_Distribute(n,P_a, a)\n",
    "  #return combination(n,l) * (P_l)**l*(1-P_l)**(n-l) * combination(N-n,a) * (P_a)**a*(1-P_a)**(N-n-a) \n",
    "\n",
    "# We put these into P_D for re-normalization, These are the probability of error we can correct\n",
    "# define separate functions for computing the probability of success\n",
    "def P_Success0(n,P_l,P_a,l,a):\n",
    "  return P_err(n,P_l, P_a,0,0)\n",
    "\n",
    "def P_Success1(n,P_l,P_a,l,a):\n",
    "  P0 = P_Success0(n, P_l, P_a,l,a)\n",
    "  P1 = P_err(n, P_l, P_a, l=0, a=1) + P_err(n, P_l, P_a, l=1, a=0)\n",
    "  return P0 + P1\n",
    "\n",
    "def P_Success2(n,P_l,P_a,l,a):\n",
    "  P1 = P_Success1(n, P_l, P_a)\n",
    "  P2 = P_err(n, P_l, P_a, l=1, a=1) + P_err(n, P_l, P_a, l=2, a=0) + P_err(n, P_l, P_a, l=0, a=2)\n",
    "  return P1 + P2\n",
    "\n",
    "def P_Success3(n,P_l,P_a,l,a):\n",
    "  P2 = P_err(n, P_l, P_a, l=1, a=1) + P_err(n, P_l, P_a, l=2, a=0) + P_err(n, P_l, P_a, l=0, a=2)\n",
    "  P3 = P_err(n, P_l, P_a,1,2) + P_err(n, P_l, P_a, 2,1) + P_err(n, P_l, P_a,3,0) + P_err(n, P_l, P_a,0,3)\n",
    "  return P2 + P3\n",
    "\n",
    "def P_D(n,P_l,P_a,l,a):\n",
    "# we only consider at most 1 error, i.e. P_0 + P_1\n",
    "  return 1 - P_Success1(n,P_l,P_a,l,a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_A(P_AB, P_D):\n",
    "    if P_D == 1:\n",
    "        return [1 for row in P_AB]\n",
    "    else:\n",
    "        return [1/(1-P_D) * sum(row) for row in P_AB] \n",
    "# sum over the elements in columns in the probability matrix P_AB\n",
    "# renormalized in P_AB already\n",
    "def P_B(P_AB, P_D):\n",
    "    if P_D == 1:\n",
    "        return [1 for col in zip(*P_AB)]\n",
    "    else:\n",
    "        return [1/(1-P_D) * sum(col) for col in zip(*P_AB)]\n",
    "\n",
    "def I_AB(H_A, H_B, H_AB, P_D):\n",
    "    if np.isnan(H_AB):\n",
    "        return 0\n",
    "    else:\n",
    "        return ((H_A + H_B - H_AB))*(1-P_D)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The matrix is a diagonal matrix with zeros for all off-diagonal elements. We can use a sparse matrix representation to save memory and computation time. However, wedon't need to reshape the sparse matrix back to a dense square matrix form (n! x n!). Instead, we can use the sparse matrix representation directly in the computations.\n",
    "\n",
    "In order to use a sparse matrix representation, we can use the scipy.sparse module. Specifically, we can use the dia_matrix class to create a diagonal sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_AB(n, P_D):\n",
    "    factorial_n = math.factorial(n)\n",
    "    diag_data = (1/factorial_n) * (1-P_D) * np.ones(factorial_n)\n",
    "    matrix = sps.dia_matrix((diag_data, 0), shape=(factorial_n, factorial_n))\n",
    "    return matrix\n",
    "\n",
    "def H_A(P_AB):\n",
    "    P_A = P_AB.diagonal()\n",
    "    H_a = np.sum(-P_A * np.log2(np.where(P_A == 0, 1, P_A)))\n",
    "    return H_a\n",
    "\n",
    "def H_B(P_AB):\n",
    "    P_B = P_AB.diagonal()\n",
    "    H_b = np.sum(-P_B * np.log2(np.where(P_B == 0, 1, P_B)))\n",
    "    return H_b\n",
    "\n",
    "def H_AB(P_AB):\n",
    "    P_AB = P_AB.diagonal()\n",
    "    P_AB = np.where(P_AB == 0, 1e-9, P_AB)  # replace zero values with 1e-9\n",
    "    H = -(P_AB * np.log2(P_AB)).sum()\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_AB_list = []\n",
    "\n",
    "P_list = np.linspace(1e-6,0.1,101)\n",
    "\n",
    "for P in P_list:\n",
    "  n = 10\n",
    "  N_n = compute_N(n) \n",
    "  P_D_val = P_D(n,P, 0,0,0)\n",
    "  \n",
    "  P_AB_val = P_AB(n, P_D_val)\n",
    "  \n",
    "  H_A_val = H_A(P_AB_val)\n",
    "  H_B_val = H_B(P_AB_val)\n",
    "  H_AB_val = H_AB(P_AB_val)\n",
    "  I_AB_val = I_AB(H_A_val, H_B_val, H_AB_val, P_D_val)\n",
    "  I_AB_list.append(I_AB_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(P_list, I_AB_list, label='I_AB renormalized', linewidth=3, alpha=1)\n",
    "\n",
    "# Add axis labels and a title\n",
    "plt.xlabel('Probability, P')\n",
    "plt.ylabel('Muutal Information, I_AB')\n",
    "\n",
    "plt.grid(color='k', linestyle='-', linewidth=0.75)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes 1 mins 29s to run n = 11, it is too slow, \n",
    "\n",
    "and it cannot perform n = 12."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "import math\n",
    "# from concurrent.futures import ProcessPoolExecutor\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def P_AB(n, P_D):\n",
    "    factorial_n = round(math.gamma(n + 1))\n",
    "    diag_data = (1 / factorial_n) * (1 - P_D) * np.ones(factorial_n)\n",
    "    matrix = sps.dia_matrix((diag_data, 0), shape=(factorial_n, factorial_n))\n",
    "    return matrix\n",
    "\n",
    "def entropy(P):\n",
    "    P_non_zero = np.where(P == 0, 1, P)\n",
    "    H = -np.sum(P * np.log2(P_non_zero))\n",
    "    return H\n",
    "\n",
    "def I_AB(H_A, H_B, H_AB, P_D):\n",
    "    if np.isnan(H_AB):\n",
    "        return 0\n",
    "    else:\n",
    "        return ((H_A + H_B - H_AB)) * (1 - P_D)\n",
    "\n",
    "def calculate_I_AB(P):\n",
    "    n = 10\n",
    "    # Assuming you have a function named 'compute_N' which was not provided in the code\n",
    "    N_n = compute_N(n)\n",
    "    P_D_val = P_D(n, P, 0, 0, 0)\n",
    "\n",
    "    P_AB_val = P_AB(n, P_D_val)\n",
    "    P_AB_diag = P_AB_val.diagonal()\n",
    "\n",
    "    H_A_val = entropy(P_AB_diag)\n",
    "    H_B_val = entropy(P_AB_diag)\n",
    "    H_AB_val = entropy(P_AB_diag)\n",
    "\n",
    "    I_AB_val = I_AB(H_A_val, H_B_val, H_AB_val, P_D_val)\n",
    "    return I_AB_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    P_list = np.linspace(1e-6, 0.1, 101)\n",
    "\n",
    "    # Using ThreadPoolExecutor for parallelization\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        I_AB_list = list(executor.map(calculate_I_AB, P_list))\n",
    "\n",
    "    return P_list, I_AB_list\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(P_list, I_AB_list, label='I_AB renormalized', linewidth=3, alpha=1)\n",
    "\n",
    "# Add axis labels and a title\n",
    "plt.xlabel('Probability, P')\n",
    "plt.ylabel('Muutal Information, I_AB')\n",
    "\n",
    "plt.grid(color='k', linestyle='-', linewidth=0.75)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can only run up to n = 11"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another test\n",
    "\n",
    "It can only run up to n = 11 too, but quite fast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.special import comb as combination\n",
    "from scipy.sparse import diags\n",
    "import scipy.sparse as sps\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.special import comb as combination\n",
    "comb_cache = {}\n",
    "#we need combination to calculate Loss_Disitribution, Add_Distribution, P_err\n",
    "# define a separate function for computing the sequence of terms used in N\n",
    "# def combination(n, r):\n",
    "#     # if r > n:\n",
    "#     #     return 0\n",
    "#     # else:\n",
    "#     return math.factorial((int(n))) / (math.factorial((int(n-r))) * math.factorial((int(r))))\n",
    "\n",
    "# def combination(n, r):\n",
    "#     if (n, r) in comb_cache:\n",
    "#         return comb_cache[(n, r)]\n",
    "#     else:\n",
    "#         comb = math.factorial(n) // (math.factorial(n-r) * math.factorial(r))\n",
    "#         comb_cache[(n, r)] = comb\n",
    "#         return comb\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def combination(n, r):\n",
    "    if r > n:\n",
    "        return 0\n",
    "    elif r == 0 or r == n:\n",
    "        return 1\n",
    "    else:\n",
    "        return combination(n-1, r-1) + combination(n-1, r)\n",
    "    \n",
    "# @lru_cache(maxsize=None)\n",
    "# def compute_N(n):\n",
    "#   def agen(): # generator of terms\n",
    "#       aset, sset, k = set(), set(), 0\n",
    "#       while True:\n",
    "#           k += 1\n",
    "#           while any(k+an in sset for an in aset): k += 1\n",
    "#           yield k; sset.update(k+an for an in aset); aset.add(k)\n",
    "#   a = list(islice(agen(), 100))\n",
    "#   photon = list(map(lambda v: v-1, a))\n",
    "#   compute_N= [sum(photon[:i]) for i in range(1,len(photon)+1)]\n",
    "#   return compute_N[n]\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def compute_N(n):\n",
    "    aset, sset, k = set(), set(), 0\n",
    "    gen_exp = (k for _ in range(100) if (k := next(i for i in range(k+1, 2*k+2) if i not in {k+an for an in aset})))\n",
    "    photon = [v-1 for v in islice(gen_exp, 100)]\n",
    "    compute_N_result = [sum(photon[:i]) for i in range(1, len(photon)+1)]\n",
    "    return compute_N_result[n]\n",
    "\n",
    "\n",
    "comb_n_cache = {}\n",
    "comb_n_M_minus_n_cache = {}\n",
    "\n",
    "\n",
    "def Loss_Distribute(n, P_l, l):\n",
    "    comb_n = combination(n, l)\n",
    "    return comb_n * (P_l)**l * (1 - P_l)**(n - l)\n",
    "\n",
    "def Add_Distribute(n, P_a, a, N_n):\n",
    "    M_minus_n = N_n - n\n",
    "    comb_Nn_Mn = combination(N_n + M_minus_n, a)\n",
    "    return comb_Nn_Mn * (P_a)**a * (1 - P_a)**(M_minus_n - a)\n",
    "\n",
    "def P_err(n, P_l, P_a, l, a, N_n):\n",
    "    return Loss_Distribute(n, P_l, l) * Add_Distribute(n, P_a, a, N_n)\n",
    "\n",
    "def P_Success0(n, P_l, P_a, l, a, N_n):\n",
    "    return P_err(n, P_l, P_a, 0, 0, N_n)\n",
    "\n",
    "def P_Success1(n, P_l, P_a, l, a, N_n):\n",
    "    P0 = P_Success0(n, P_l, P_a, l, a, N_n)\n",
    "    P1 = P_err(n, P_l, P_a, 0, 1, N_n) + P_err(n, P_l, P_a, 1, 0, N_n)\n",
    "    return P0 + P1\n",
    "\n",
    "def P_D(n, P_l, P_a, l, a, N_n):\n",
    "    return 1 - P_Success1(n, P_l, P_a, l, a, N_n)\n",
    "\n",
    "def I_AB(H_A, H_B, H_AB, P_D):\n",
    "    if np.isnan(H_AB):\n",
    "        return 0\n",
    "    else:\n",
    "        return ((H_A + H_B - H_AB))*(1-P_D)\n",
    "\n",
    "def P_AB(n, P_D):\n",
    "    factorial_n = round(math.gamma(n + 1))\n",
    "    diag_data = (1 / factorial_n) * (1 - P_D) * np.ones(factorial_n)\n",
    "    matrix = sps.dia_matrix((diag_data, 0), shape=(factorial_n, factorial_n))\n",
    "    return matrix\n",
    "\n",
    "# def P_AB(n, P_D):\n",
    "#     factorial_n = round(math.gamma(n + 1))\n",
    "#     diag_data = (1 / factorial_n) * (1 - P_D) * np.ones((P_D.shape[0], factorial_n))\n",
    "#     matrix = sps.dia_matrix((diag_data, np.zeros(P_D.shape[0])), shape=(P_D.shape[0], factorial_n, factorial_n))\n",
    "#     return matrix\n",
    "\n",
    "# def P_AB(n, P_D):\n",
    "#     factorial_n = round(math.gamma(n + 1))\n",
    "#     diag_data = (1 / factorial_n) * (1 - P_D) * np.ones((P_D.shape[0], factorial_n))\n",
    "#     matrix = sps.dia_matrix((diag_data, np.zeros(diag_data.shape[1])), shape=(diag_data.shape[0], diag_data.shape[1], diag_data.shape[1]))\n",
    "#     return matrix\n",
    "\n",
    "# def P_AB(n, P_D):\n",
    "#     factorial_n = round(math.gamma(n + 1))\n",
    "#     diag_data = (1 / factorial_n) * (1 - P_D) * np.ones((P_D.shape[0], factorial_n))\n",
    "#     matrix = sps.dia_matrix((diag_data, [0]), shape=(diag_data.shape[0], diag_data.shape[1]))\n",
    "# #     return matrix\n",
    "\n",
    "# def P_AB(n, P_D):\n",
    "#     P_D = np.asarray(P_D)\n",
    "#     factorial_n = round(math.gamma(n + 1))\n",
    "#     diag_data = (1 / factorial_n) * (1 - P_D) * np.ones((P_D.shape[0], factorial_n))\n",
    "#     offsets = np.zeros((1,), dtype=int)\n",
    "#     matrix = sps.dia_matrix((diag_data, offsets), shape=(diag_data.shape[0], diag_data.shape[1]))\n",
    "#     return matrix.toarray()\n",
    "\n",
    "# def P_AB(n, P_D):\n",
    "#     P_D = np.asarray(P_D)\n",
    "#     factorial_n = round(math.gamma(n + 1))\n",
    "#     diag_data = np.array([(1 / factorial_n) * (1 - p) * np.ones(factorial_n) for p in P_D])\n",
    "#     offsets = np.zeros((1,), dtype=int)\n",
    "#     matrices = [sps.dia_matrix((data, offsets), shape=(factorial_n, factorial_n)).toarray() for data in diag_data]\n",
    "#     return np.stack(matrices)\n",
    "\n",
    "def entropy(P):\n",
    "    P_non_zero = np.where(P == 0, 1, P)\n",
    "    H = -np.sum(P * np.log2(P_non_zero))\n",
    "    return H\n",
    "\n",
    "def H_A(P_AB):\n",
    "    P_A = P_AB.diagonal()\n",
    "    return -np.sum(P_A * np.log2(np.where(P_A == 0, 1, P_A)))\n",
    "\n",
    "def H_B(P_AB):\n",
    "    P_B = P_AB.diagonal()\n",
    "    return -np.sum(P_B * np.log2(np.where(P_B == 0, 1, P_B)))\n",
    "\n",
    "def H_AB(P_AB):\n",
    "    P_AB = P_AB.diagonal()\n",
    "    P_AB = np.where(P_AB == 0, 1e-9, P_AB)  # replace zero values with 1e-9\n",
    "    return -(P_AB * np.log2(P_AB)).sum()\n",
    "\n",
    "# Rest of the code remains the same\n",
    "\n",
    "\n",
    "# def compute_mutual_information(P_list, n, N_n):\n",
    "#     P_l = P_list[:, np.newaxis, np.newaxis, np.newaxis, np.newaxis]\n",
    "#     P_a = np.zeros_like(P_l)\n",
    "#     l, a = np.meshgrid(np.arange(n + 1), np.arange(N_n - n + 1), indexing='ij')\n",
    "\n",
    "#     P_err_val = P_err(n, P_l, P_a, l, a, N_n)\n",
    "#     P_D_val = P_D(n, P_l, P_a, l, a, N_n)\n",
    "\n",
    "#     P_AB_val = P_AB(n, P_D_val)\n",
    "#     H_A_val = entropy(P_AB_val.diagonal())\n",
    "#     H_B_val = entropy(P_AB_val.diagonal())\n",
    "#     H_AB_val = entropy(P_AB_val.diagonal())\n",
    "#     I_AB_val = I_AB(H_A_val, H_B_val, H_AB_val, P_D_val)\n",
    "\n",
    "#     return I_AB_val\n",
    "\n",
    "def compute_mutual_information(P_list, n, N_n):\n",
    "    P_l = P_list[:, np.newaxis, np.newaxis]\n",
    "    P_a = np.zeros_like(P_l)\n",
    "    l, a = np.meshgrid(np.arange(n + 1), np.arange(N_n - n + 1), indexing='ij')\n",
    "    \n",
    "    P_err_val = P_err(n, P_l, P_a, l, a, N_n)\n",
    "    P_D_val = P_D(n, P_l, P_a, l, a, N_n)\n",
    "\n",
    "    P_AB_val = P_AB(n, P_D_val)\n",
    "    H_A_val = entropy(P_AB_val.diagonal())\n",
    "    H_B_val = entropy(P_AB_val.diagonal())\n",
    "    H_AB_val = entropy(P_AB_val.diagonal())\n",
    "    I_AB_val = I_AB(H_A_val, H_B_val, H_AB_val, P_D_val)\n",
    "\n",
    "#     return I_AB_val\n",
    "\n",
    "I_AB_list = []\n",
    "\n",
    "P_list = np.linspace(1e-6, 0.1, 101)\n",
    "\n",
    "# n = 5\n",
    "\n",
    "# N_n = compute_N(n)\n",
    "\n",
    "# I_AB_val = compute_mutual_information(P_list, n, N_n)\n",
    "# I_AB_list = I_AB_val.reshape(-1).tolist()\n",
    "\n",
    "for P in P_list:\n",
    "    n = 10\n",
    "    N_n = compute_N(n)\n",
    "    P_D_val = P_D(n, P, 0, 0, 0, N_n)\n",
    "\n",
    "    P_AB_val = P_AB(n, P_D_val)\n",
    "\n",
    "    # H_A_val = H_A(P_AB_val)\n",
    "    # H_B_val = H_B(P_AB_val)\n",
    "    # H_AB_val = H_AB(P_AB_val)\n",
    "    # I_AB_val = I_AB(H_A_val, H_B_val, H_AB_val, P_D_val)\n",
    "    # I_AB_list.append(I_AB_val)\n",
    "    H_A_val = entropy(P_AB_val.diagonal())\n",
    "    H_B_val = entropy(P_AB_val.diagonal())\n",
    "    H_AB_val = entropy(P_AB_val.diagonal())\n",
    "    I_AB_val = I_AB(H_A_val, H_B_val, H_AB_val, P_D_val)\n",
    "    I_AB_list.append(I_AB_val)\n",
    "\n",
    "plt.plot(P_list, I_AB_list, label='I_AB renormalized', linewidth=3, alpha=1)\n",
    "\n",
    "plt.xlabel('Probability, P')\n",
    "plt.ylabel('Mutual Information, I_AB')\n",
    "\n",
    "plt.grid(color='k', linestyle='-', linewidth=0.75)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It runs more than 35 mins, it is not practical  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probably the fastest right now\n",
    "\n",
    "It works only up to n = 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from functools import lru_cache\n",
    "from itertools import islice\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "comb_cache = {}\n",
    "comb_n_cache = {}\n",
    "comb_n_M_minus_n_cache = {}\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def combination(n, r):\n",
    "    if r > n:\n",
    "        return 0\n",
    "    elif r == 0 or r == n:\n",
    "        return 1\n",
    "    else:\n",
    "        return combination(n-1, r-1) + combination(n-1, r)\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def compute_N(n):\n",
    "    aset, sset, k = set(), set(), 0\n",
    "    gen_exp = (k for _ in range(100) if (k := next(i for i in range(k+1, 2*k+2) if i not in {k+an for an in aset})))\n",
    "    photon = [v-1 for v in islice(gen_exp, 100)]\n",
    "    compute_N_result = [sum(photon[:i]) for i in range(1, len(photon)+1)]\n",
    "    return compute_N_result[n]\n",
    "\n",
    "def Loss_Distribute(n, P_l, l):\n",
    "    comb_n = combination(n, l)\n",
    "    return comb_n * (P_l)**l * (1 - P_l)**(n - l)\n",
    "\n",
    "def Add_Distribute(n, P_a, a, N_n):\n",
    "    M_minus_n = N_n - n\n",
    "    comb_Nn_Mn = combination(N_n + M_minus_n, a)\n",
    "    return comb_Nn_Mn * (P_a)**a * (1 - P_a)**(M_minus_n - a)\n",
    "\n",
    "def P_err(n, P_l, P_a, l, a, N_n):\n",
    "    return Loss_Distribute(n, P_l, l) * Add_Distribute(n, P_a, a, N_n)\n",
    "\n",
    "def P_Success0(n, P_l, P_a, l, a, N_n):\n",
    "    return P_err(n, P_l, P_a, 0, 0, N_n)\n",
    "\n",
    "def P_Success1(n, P_l, P_a, l, a, N_n):\n",
    "    P0 = P_Success0(n, P_l, P_a, l, a, N_n)\n",
    "    P1 = P_err(n, P_l, P_a, 0, 1, N_n) + P_err(n, P_l, P_a, 1, 0, N_n)\n",
    "    return P0 + P1\n",
    "\n",
    "def P_D(n, P_l, P_a, l, a, N_n):\n",
    "    return 1 - P_Success1(n, P_l, P_a, l, a, N_n)\n",
    "\n",
    "def I_AB(H_A, H_B, H_AB, P_D):\n",
    "    if np.isnan(H_AB):\n",
    "        return 0\n",
    "    else:\n",
    "        return ((H_A + H_B - H_AB))*(1-P_D)\n",
    "\n",
    "precomputed_matrices = {}\n",
    "\n",
    "def precompute_diagonal_matrices(max_n, P_D_list):\n",
    "    for n in range(2, max_n + 1):\n",
    "        for P_D in P_D_list:\n",
    "            factorial_n = round(math.gamma(n + 1))\n",
    "            diag_data = (1 / factorial_n) * (1 - P_D) * np.ones(factorial_n)\n",
    "            matrix = np.diag(diag_data)\n",
    "            precomputed_matrices[(n, P_D)] = matrix\n",
    "\n",
    "def P_AB(n, P_D):\n",
    "    return precomputed_matrices.get((n, P_D))\n",
    "\n",
    "# max_n = 11\n",
    "# P_D_list = [P_D(11, 0, 0, 0, 0, N_n) for P in np.linspace(1e-6, 0.1, 101)]\n",
    "# precompute_diagonal_matrices(max_n, P_D_list)\n",
    "\n",
    "# def P_AB(n, P_D):\n",
    "#     factorial_n = round(math.gamma(n + 1))\n",
    "#     diag_data = (1 / factorial_n) * (1 - P_D) * np.ones(factorial_n)\n",
    "#     matrix = sps.dia_matrix((diag_data, 0), shape=(factorial_n, factorial_n))\n",
    "#     return matrix\n",
    "\n",
    "# def compute_diag_elements(n, P_D):\n",
    "#     factorial_n = round(math.gamma(n + 1))\n",
    "#     diag_data = (1 / factorial_n) * (1 - P_D) * np.ones(factorial_n)\n",
    "#     return diag_data\n",
    "\n",
    "# Modify the entropy function to work with diagonal elements directly\n",
    "def entropy_diag_elements(diag_elements):\n",
    "    P_non_zero = np.where(diag_elements == 0, 1, diag_elements)\n",
    "    H = -np.sum(diag_elements * np.log2(P_non_zero))\n",
    "    return H\n",
    "\n",
    "def entropy(P):\n",
    "    P_non_zero = np.where(P == 0, 1, P)\n",
    "    H = -np.sum(P * np.log2(P_non_zero))\n",
    "    return H\n",
    "\n",
    "def H_A(diag_elements):\n",
    "    return entropy_diag_elements(diag_elements)\n",
    "\n",
    "def H_B(diag_elements):\n",
    "    return entropy_diag_elements(diag_elements)\n",
    "\n",
    "def H_AB(diag_elements):\n",
    "    return entropy_diag_elements(diag_elements)\n",
    "\n",
    "# def H_A(P_AB):\n",
    "#     P_A = P_AB.diagonal()\n",
    "#     return -np.sum(P_A * np.log2(np.where(P_A == 0, 1, P_A)))\n",
    "\n",
    "# def H_B(P_AB):\n",
    "#     P_B = P_AB.diagonal()\n",
    "#     return -np.sum(P_B * np.log2(np.where(P_B == 0, 1, P_B)))\n",
    "\n",
    "# def H_AB(P_AB):\n",
    "#     P_AB = P_AB.diagonal()\n",
    "#     P_AB = np.where(P_AB == 0, 1e-9, P_AB)  # replace zero values with 1e-9\n",
    "#     return -(P_AB * np.log2(P_AB)).sum()\n",
    "\n",
    "\n",
    "# def compute_mutual_information(P_list, n, N_n):\n",
    "#     P_l = P_list[:, np.newaxis, np.newaxis]\n",
    "#     P_a = np.zeros_like(P_l)\n",
    "#     l, a = np.meshgrid(np.arange(n + 1), np.arange(N_n - n + 1), indexing='ij')\n",
    "    \n",
    "#     P_err_val = P_err(n, P_l, P_a, l, a, N_n)\n",
    "#     P_D_val = P_D(n, P_l, P_a, l, a, N_n)\n",
    "\n",
    "#     P_AB_val = P_AB(n, P_D_val)\n",
    "#     H_A_val = entropy(P_AB_val.diagonal())\n",
    "#     H_B_val = entropy(P_AB_val.diagonal())\n",
    "#     H_AB_val = entropy(P_AB_val.diagonal())\n",
    "#     I_AB_val = I_AB(H_A_val, H_B_val, H_AB_val, P_D_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from functools import lru_cache\n",
    "from itertools import islice\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "comb_cache = {}\n",
    "comb_n_cache = {}\n",
    "comb_n_M_minus_n_cache = {}\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def combination(n, r):\n",
    "    if r > n:\n",
    "        return 0\n",
    "    elif r == 0 or r == n:\n",
    "        return 1\n",
    "    else:\n",
    "        return combination(n-1, r-1) + combination(n-1, r)\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def compute_N(n):\n",
    "    aset, sset, k = set(), set(), 0\n",
    "    gen_exp = (k for _ in range(100) if (k := next(i for i in range(k+1, 2*k+2) if i not in {k+an for an in aset})))\n",
    "    photon = [v-1 for v in islice(gen_exp, 100)]\n",
    "    compute_N_result = [sum(photon[:i]) for i in range(1, len(photon)+1)]\n",
    "    return compute_N_result[n]\n",
    "\n",
    "def Loss_Distribute(n, P_l, l):\n",
    "    comb_n = combination(n, l)\n",
    "    return comb_n * (P_l)**l * (1 - P_l)**(n - l)\n",
    "\n",
    "def Add_Distribute(n, P_a, a, N_n):\n",
    "    M_minus_n = N_n - n\n",
    "    comb_Nn_Mn = combination(N_n + M_minus_n, a)\n",
    "    return comb_Nn_Mn * (P_a)**a * (1 - P_a)**(M_minus_n - a)\n",
    "\n",
    "def P_err(n, P_l, P_a, l, a, N_n):\n",
    "    return Loss_Distribute(n, P_l, l) * Add_Distribute(n, P_a, a, N_n)\n",
    "\n",
    "def P_Success0(n, P_l, P_a, l, a, N_n):\n",
    "    return P_err(n, P_l, P_a, 0, 0, N_n)\n",
    "\n",
    "def P_Success1(n, P_l, P_a, l, a, N_n):\n",
    "    P0 = P_Success0(n, P_l, P_a, l, a, N_n)\n",
    "    P1 = P_err(n, P_l, P_a, 0, 1, N_n) + P_err(n, P_l, P_a, 1, 0, N_n)\n",
    "    return P0 + P1\n",
    "\n",
    "def P_D(n, P_l, P_a, l, a, N_n):\n",
    "    return 1 - P_Success1(n, P_l, P_a, l, a, N_n)\n",
    "\n",
    "def I_AB(H_A, H_B, H_AB, P_D):\n",
    "    if np.isnan(H_AB):\n",
    "        return 0\n",
    "    else:\n",
    "        return ((H_A + H_B - H_AB))*(1-P_D)\n",
    "\n",
    "precomputed_matrices = {}\n",
    "\n",
    "def precompute_diagonal_matrices(max_n, P_D_list):\n",
    "    for n in range(2, max_n + 1):\n",
    "        for P_D in P_D_list:\n",
    "            factorial_n = round(math.gamma(n + 1))\n",
    "            diag_data = (1 / factorial_n) * (1 - P_D) * np.ones(factorial_n)\n",
    "            matrix = np.diag(diag_data)\n",
    "            precomputed_matrices[(n, P_D)] = matrix\n",
    "\n",
    "def P_AB(n, P_D):\n",
    "    return precomputed_matrices.get((n, P_D))\n",
    "\n",
    "# Modify the entropy function to work with diagonal elements directly\n",
    "def entropy_diag_elements(diag_elements):\n",
    "    P_non_zero = np.where(diag_elements == 0, 1, diag_elements)\n",
    "    H = -np.sum(diag_elements * np.log2(P_non_zero))\n",
    "    return H\n",
    "\n",
    "def entropy(P):\n",
    "    P_non_zero = np.where(P == 0, 1, P)\n",
    "    H = -np.sum(P * np.log2(P_non_zero))\n",
    "    return H\n",
    "\n",
    "def H_A(diag_elements):\n",
    "    return entropy_diag_elements(diag_elements)\n",
    "\n",
    "def H_B(diag_elements):\n",
    "    return entropy_diag_elements(diag_elements)\n",
    "\n",
    "def H_AB(diag_elements):\n",
    "    return entropy_diag_elements(diag_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_I_AB_BPPM(P, n):\n",
    "    N_n = compute_N(n)\n",
    "    P_D_val = P_D(n, P, 0, 0, 0, N_n)\n",
    "\n",
    "    diag_elements = (1 / math.gamma(n + 1)) * (1 - P_D_val) * np.ones(round(math.gamma(n + 1)))\n",
    "\n",
    "    H_A_val = entropy_diag_elements(diag_elements)\n",
    "    H_B_val = entropy_diag_elements(diag_elements)\n",
    "    H_AB_val = entropy_diag_elements(diag_elements)\n",
    "    I_AB_val = I_AB(H_A_val, H_B_val, H_AB_val, P_D_val)\n",
    "\n",
    "    return I_AB_val\n",
    "\n",
    "n = 10\n",
    "num_workers = 8  # Set to the number of CPU cores available on your system\n",
    "P_list = np.linspace(1e-6, 0.1, 101)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    I_AB_BPPM_list_12 = list(executor.map(lambda P: calculate_I_AB_BPPM(P, n), P_list))\n",
    "\n",
    "plt.plot(P_list, I_AB_BPPM_list_12)\n",
    "plt.xlabel('P')\n",
    "plt.ylabel('I_AB_BPPM')\n",
    "plt.title('Mutual Information vs P for n = 12')\n",
    "plt.grid(color='k', linestyle='-', linewidth=0.75)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from functools import lru_cache\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pandas as pd\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def compute_N(n):\n",
    "    aset, sset, k = set(), set(), 0\n",
    "    gen_exp = (k for _ in range(100) if (k := next(i for i in range(k+1, 2*k+2) if i not in {k+an for an in aset})))\n",
    "    photon = [v-1 for v in islice(gen_exp, 100)]\n",
    "    compute_N_result = [sum(photon[:i]) for i in range(1, len(photon)+1)]\n",
    "    return compute_N_result[n]\n",
    "\n",
    "def P_err(n, P_l, P_a, l, a, N_n):\n",
    "    return Loss_Distribute(n, P_l, l) * Add_Distribute(n, P_a, a, N_n)\n",
    "\n",
    "def P_D(n, P_l, P_a, l, a, N_n):\n",
    "    return 1 - P_Success1(n, P_l, P_a, l, a, N_n)\n",
    "\n",
    "# def P_AB(n, P_D):\n",
    "#     factorial_n = round(math.gamma(n + 1))\n",
    "#     diag_data = (1 / factorial_n) * (1 - P_D) * np.ones(factorial_n)\n",
    "#     return diag_data\n",
    "\n",
    "def entropy_diag_elements(diag_elements):\n",
    "    P_non_zero = np.where(diag_elements == 0, 1, diag_elements)\n",
    "    H = -np.sum(diag_elements * np.log2(P_non_zero))\n",
    "    return H\n",
    "\n",
    "def H_A(diag_elements):\n",
    "    return entropy_diag_elements(diag_elements)\n",
    "\n",
    "def H_B(diag_elements):\n",
    "    return entropy_diag_elements(diag_elements)\n",
    "\n",
    "def H_AB(diag_elements):\n",
    "    return entropy_diag_elements(diag_elements)\n",
    "\n",
    "def I_AB(H_A, H_B, H_AB, P_D):\n",
    "    if np.isnan(H_AB):\n",
    "        return 0\n",
    "    else:\n",
    "        return ((H_A + H_B - H_AB))*(1-P_D)\n",
    "\n",
    "def calculate_I_AB_BPPM(P, n):\n",
    "    N_n = compute_N(n)\n",
    "    P_D_val = P_D(n, P, 0, 0, 0, N_n)\n",
    "\n",
    "    diag_elements = P_AB(n, P_D_val)\n",
    "\n",
    "    H_A_val = H_A(diag_elements)\n",
    "    H_B_val = H_B(diag_elements)\n",
    "    H_AB_val = H_AB(diag_elements)\n",
    "    I_AB_val = I_AB(H_A_val, H_B_val, H_AB_val, P_D_val)\n",
    "\n",
    "    return I_AB_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 10\n",
    "# P_list = np.linspace(1e-6, 0.1, 101)\n",
    "# num_workers = 8  # Set to the number of CPU cores available on your system\n",
    "\n",
    "# with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "#     I_AB_BPPM_list_12 = list(executor.map(lambda P: calculate_I_AB_BPPM(P, n), P_list))\n",
    "\n",
    "# plt.plot(P_list, I_AB_BPPM_list_12)\n",
    "# plt.xlabel('P')\n",
    "# plt.ylabel('I_AB')\n",
    "# plt.title('Mutual Information I_AB for n = 12')\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_of_matrix(n):\n",
    "    factorial_n = round(math.gamma(n + 1))\n",
    "    return factorial_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_of_matrix(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones(size_of_matrix(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix_size = pd.DataFrame(columns = ['number',\n",
    "                                         'Time Bin',\n",
    "                                         'factorial',\n",
    "                                         'size',\n",
    "                                         'Detectio Probability' \n",
    "                                        ]\n",
    "                                        )\n",
    "\n",
    "for n in range(1,21):\n",
    "    N_n = compute_N(n)\n",
    "    factorial_n = round(math.gamma(n + 1))\n",
    "    matrix_size_val = factorial_n * factorial_n\n",
    "    P_D_val =  P_D(n, 0, 0, 0, 0, N_n)\n",
    "    \n",
    "    df_matrix_size.loc[n-1] = [n, N_n, factorial_n, matrix_size_val, P_D_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " N_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix_size.iloc[3,1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix_size.iloc[3,2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def P_D(n, P_l, P_a, l, a, N_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_D(4, 0, 0, 0, 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_D(4, 0, 0, 0, 0, df_matrix_size.iloc[ 4 -1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix_size.iloc[4,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_AB(n, P_D):\n",
    "    diag_data = (1 / df_matrix_size.iloc[n -1, 2]) * (1 - df_matrix_size.iloc[ n - 1 ,4]) * np.ones(df_matrix_size.iloc[ n-1, 2])\n",
    "    return diag_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_diag_elements(n, P_D):\n",
    "    # factorial_n = round(math.gamma(n + 1))\n",
    "    diag_data = (1 / df_matrix_size.iloc[n -1, 2]) * (1 - P_D) * np.ones(int(df_matrix_size.iloc[ n-1, 2]))\n",
    "    return diag_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_diag_elements(5, P_D(5, 0, 0, 0, 0, df_matrix_size.iloc[ 5, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix_size.iloc[10 -1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_N(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix_size = pd.DataFrame(columns = ['number',\n",
    "                                         'Time Bin',\n",
    "                                         'factorial',\n",
    "                                         'size',\n",
    "                                         'Detectio Probability' \n",
    "                                        ]\n",
    "                                        )\n",
    "\n",
    "for n in range(1,21):\n",
    "    N_n = compute_N(n)\n",
    "    factorial_n = round(math.gamma(n + 1))\n",
    "    matrix_size_val = factorial_n * factorial_n\n",
    "    P_D_val =  P_D(n, 0, 0, 0, 0, N_n)\n",
    "    \n",
    "    df_matrix_size.loc[n-1] = [n, N_n, factorial_n, matrix_size_val, P_D_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_list = np.linspace(1e-6, 0.1, 101)\n",
    "\n",
    "df_P_D = pd.DataFrame(columns = ['P',\n",
    "                                'P_D'\n",
    "                                ]\n",
    "                                )\n",
    "n = 12\n",
    "for P in P_list:\n",
    "\n",
    "    P_D_val = P_D(n, P, 0, 0, 0, int(df_matrix_size.iloc[n -1,1]))\n",
    "    \n",
    "        # Append the new row to the DataFrame\n",
    "    df_P_D = df_P_D.append({'P': P, 'P_D': P_D_val}, ignore_index=True)\n",
    "# Display the DataFrame\n",
    "# print(df_P_D)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_P_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_P_D.iloc[1 - 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix_size.iloc[1,2 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_D(1, 0, 0, 0, 0, df_matrix_size.iloc[1,2 + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_D(10, 1e-6, 0, 0, 0, df_matrix_size.iloc[10 -1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_P_D.iloc[1 - 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P_list = np.linspace(1e-6, 0.1, 101)\n",
    "\n",
    "# df_P_D = pd.DataFrame(columns = ['P',\n",
    "#                                 'P_D'\n",
    "#                                 ]\n",
    "#                                 )\n",
    "# n = 12\n",
    "# for P in P_list:\n",
    "\n",
    "#     P_D_val = P_D(n, P, 0, 0, 0, int(df_matrix_size.iloc[n -1,1]))\n",
    "    \n",
    "#         # Append the new row to the DataFrame\n",
    "#     df_P_D = df_P_D.append({'P': P, 'P_D': P_D_val}, ignore_index=True)\n",
    "# # Display the DataFrame\n",
    "# # print(df_P_D)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_diag_elements(n, P_D, df_matrix_size):\n",
    "    factorial_n = df_matrix_size.loc[n - 1, 'factorial']\n",
    "    diag_data = (1 / factorial_n) * (1 - P_D) * np.ones(int(factorial_n))\n",
    "    return diag_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# def calculate_I_AB_BPPM(P, n, df_P_D, df_matrix_size):\n",
    "#     # Find the row with the desired P value\n",
    "#     row = df_P_D[df_P_D['P'] == P]\n",
    "\n",
    "#     # Extract the corresponding P_D value\n",
    "#     P_D_val = row['P_D'].values[0]\n",
    "\n",
    "#     diag_elements = compute_diag_elements(n, P_D_val, df_matrix_size)\n",
    "\n",
    "#     H_A_val = H_A(diag_elements)\n",
    "#     H_B_val = H_B(diag_elements)\n",
    "#     H_AB_val = H_AB(diag_elements)\n",
    "#     I_AB_val = I_AB(H_A_val, H_B_val, H_AB_val, P_D_val)\n",
    "\n",
    "#     return I_AB_val\n",
    "\n",
    "\n",
    "# n = 12\n",
    "# num_workers = 8  # Set to the number of CPU cores available on your system\n",
    "\n",
    "# with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "#     I_AB_BPPM_list_11 = list(executor.map(lambda P: calculate_I_AB_BPPM(P, n, df_P_D, df_matrix_size), P_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(P_list, I_AB_BPPM_list_11, label='I_AB renormalized', linewidth=3, alpha=1)\n",
    "\n",
    "# plt.xlabel('Probability, P')\n",
    "# plt.ylabel('Mutual Information, I_AB')\n",
    "\n",
    "# plt.grid(color='k', linestyle='-', linewidth=0.75)\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import islice\n",
    "from functools import lru_cache\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "# from concurrent.futures import ProcessPoolExecutor\n",
    "from numba import njit, int64, float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=None)\n",
    "def compute_N(n):\n",
    "  def agen(): # generator of terms\n",
    "      aset, sset, k = set(), set(), 0\n",
    "      while True:\n",
    "          k += 1\n",
    "          while any(k+an in sset for an in aset): k += 1\n",
    "          yield k; sset.update(k+an for an in aset); aset.add(k)\n",
    "  a = list(islice(agen(), 100))\n",
    "  photon = list(map(lambda v: v-1, a))\n",
    "  compute_N= [sum(photon[:i]) for i in range(1,len(photon)+1)]\n",
    "  return compute_N[n]\n",
    "\n",
    "@njit\n",
    "# @lru_cache(maxsize=None)\n",
    "def combination(n, r):\n",
    "    if r > n:\n",
    "        return 0\n",
    "    elif r == 0 or r == n:\n",
    "        return 1\n",
    "    else:\n",
    "        return combination(n-1, r-1) + combination(n-1, r)\n",
    "\n",
    "@njit(float64(int64, float64, int64))\n",
    "def Loss_Distribute(n, P_l, l):\n",
    "    comb_n = combination(n, l)\n",
    "    return comb_n * (P_l)**l * (1 - P_l)**(n - l)\n",
    "\n",
    "@njit(float64(int64, float64, int64, int64))\n",
    "def Add_Distribute(n, P_a, a, N_n):\n",
    "    M_minus_n = N_n - n\n",
    "    comb_Nn_Mn = combination(N_n + M_minus_n, a)\n",
    "    return comb_Nn_Mn * (P_a)**a * (1 - P_a)**(M_minus_n - a)\n",
    "\n",
    "@njit(float64(int64, float64, float64, int64, int64, int64))\n",
    "def P_err(n, P_l, P_a, l, a, N_n):\n",
    "    return Loss_Distribute(n, P_l, l) * Add_Distribute(n, P_a, a, N_n)\n",
    "\n",
    "@njit(float64(int64, float64, float64, int64, int64, int64))\n",
    "def P_Success0(n, P_l, P_a, l, a, N_n):\n",
    "    return P_err(n, P_l, P_a, 0, 0, N_n)\n",
    "\n",
    "@njit(float64(int64, float64, float64, int64, int64, int64))\n",
    "def P_Success1(n, P_l, P_a, l, a, N_n):\n",
    "    P0 = P_Success0(n, P_l, P_a, l, a, N_n)\n",
    "    P1 = P_err(n, P_l, P_a, 0, 1, N_n) + P_err(n, P_l, P_a, 1, 0, N_n)\n",
    "    return P0 + P1\n",
    "\n",
    "# @njit(float64(int64, float64, float64, int64, int64, int64))\n",
    "# def P_D(n, P_l, P_a, l, a, N_n):\n",
    "#     return 1 - P_Success1(n, P_l, P_a, l, a, N_n)\n",
    "\n",
    "\n",
    "eps = np.finfo(float).eps\n",
    "\n",
    "@njit(float64(float64[:], float64))\n",
    "def entropy_diag_elements(diag_elements, eps=1e-10):  # Add a default value for the 'eps' parameter\n",
    "    H = 0.0\n",
    "    for p in diag_elements:\n",
    "        if p == 0:\n",
    "            p = eps\n",
    "        H -= p * np.log2(p)\n",
    "    return H\n",
    "\n",
    "\n",
    "# Re-run the code with the updated function\n",
    "\n",
    "\n",
    "# @njit(float64(float64[:]))\n",
    "# def entropy_diag_elements(diag_elements):\n",
    "#     P_non_zero = np.where(diag_elements == 0, np.finfo(float).eps, diag_elements)\n",
    "\n",
    "#     H = -np.sum(diag_elements * np.log2(P_non_zero))\n",
    "#     return H\n",
    "\n",
    "def H_A(diag_elements, eps=1e-10):\n",
    "    return entropy_diag_elements(diag_elements, eps)\n",
    "\n",
    "def H_B(diag_elements, eps=1e-10):\n",
    "    return entropy_diag_elements(diag_elements, eps)\n",
    "\n",
    "def H_AB(diag_elements, eps=1e-10):\n",
    "    return entropy_diag_elements(diag_elements, eps)\n",
    "\n",
    "\n",
    "@njit(float64(int64, float64, int64, int64))\n",
    "def I_AB(H_A, H_B, H_AB, P_D):\n",
    "    if np.isnan(H_AB):\n",
    "        return 0\n",
    "    else:\n",
    "        return ((H_A + H_B - H_AB))*(1-P_D)\n",
    "\n",
    "def compute_diag_elements(n, P_D_val, df_matrix_size):\n",
    "    factorial_n = df_matrix_size.loc[n - 1, 'factorial']\n",
    "    diag_data = (1 / factorial_n) * (1 - P_D_val) * np.ones(int(factorial_n))\n",
    "    return diag_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix_size = pd.DataFrame(columns = ['number',\n",
    "                                         'Time Bin',\n",
    "                                         'factorial',\n",
    "                                         'size'\n",
    "                                         \n",
    "                                        ]\n",
    "                                        )\n",
    "\n",
    "for n in range(1,21):\n",
    "    N_n = compute_N(n)\n",
    "    factorial_n = round(math.gamma(n + 1))\n",
    "    matrix_size_val = factorial_n * factorial_n\n",
    "    \n",
    "    df_matrix_size.loc[n-1] = [n, N_n, factorial_n, matrix_size_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_D(n, P_l, P_a, l, a, matrix_sizes):\n",
    "    N_n = matrix_sizes[n]['N_n']\n",
    "    factorial_n = matrix_sizes[n]['factorial_n']\n",
    "    matrix_size_val = matrix_sizes[n]['matrix_size_val']\n",
    "    \n",
    "    # Compute the probability of error\n",
    "    P_error = 1 - P_Success1(n, P_l, P_a, l, a, N_n)\n",
    "    \n",
    "    return P_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_sizes = {}\n",
    "\n",
    "for n in range(1, 21):\n",
    "    N_n = compute_N(n)\n",
    "    factorial_n = round(math.gamma(n + 1))\n",
    "    matrix_size_val = factorial_n * factorial_n\n",
    "    \n",
    "    matrix_sizes[n] = {\n",
    "        'n':n,\n",
    "        'N_n': N_n,\n",
    "        'factorial_n': factorial_n,\n",
    "        'matrix_size_val': factorial_n * factorial_n\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_list = np.linspace(1e-6, 0.1, 101)\n",
    "\n",
    "n = 11\n",
    "\n",
    "# df_P_D = pd.DataFrame(columns=['P', 'P_D'])\n",
    "\n",
    "\n",
    "df_P_D = pd.DataFrame([(P, P_D(n, P, 0, 0, 0, matrix_sizes)) for P in P_list], columns=['P', 'P_D'])\n",
    "\n",
    "\n",
    "# df_P_D = pd.DataFrame([(P, P_D(n, P, 0, 0, 0, int(df_matrix_size.iloc[n - 1, 1]))) for P in P_list], columns=['P', 'P_D'])\n",
    "\n",
    "\n",
    "for P in P_list:\n",
    "    P_D_val = P_D(n, P, 0, 0, 0, matrix_sizes)  # fix here\n",
    "\n",
    "    # Create a new DataFrame for the current row and concatenate it to the existing DataFrame\n",
    "    new_row = pd.DataFrame({'P': [P], 'P_D': [P_D_val]})\n",
    "    df_P_D = pd.concat([df_P_D, new_row], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_matrix_sizes(max_n):\n",
    "    matrix_sizes = {}\n",
    "    for n in range(1, max_n+1):\n",
    "        N_n = compute_N(n)\n",
    "        factorial_n = round(math.gamma(n + 1))\n",
    "        matrix_size_val = factorial_n * factorial_n\n",
    "        matrix_sizes[n] = {'N_n': N_n, 'factorial_n': factorial_n, 'matrix_size_val': matrix_size_val}\n",
    "    return matrix_sizes\n",
    "\n",
    "# Example usage:\n",
    "max_n = 20\n",
    "matrix_sizes = precompute_matrix_sizes(max_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_values(n, P_to_PD, matrix_sizes):\n",
    "    precomputed_values = {}\n",
    "    \n",
    "    for P in P_to_PD:\n",
    "        P_D_val = P_to_PD[P]\n",
    "        diag_elements = compute_diag_elements(n, P_D_val, matrix_sizes)\n",
    "        H_A_val = H_A(diag_elements)\n",
    "        H_B_val = H_B(diag_elements)\n",
    "        H_AB_val = H_AB(diag_elements)\n",
    "        \n",
    "        precomputed_values[P] = {\n",
    "            'diag_elements': diag_elements,\n",
    "            'H_A_val': H_A_val,\n",
    "            'H_B_val': H_B_val,\n",
    "            'H_AB_val': H_AB_val\n",
    "        }\n",
    "    \n",
    "    return precomputed_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_I_AB_BPPM_optimized(P, n, P_to_PD, precomputed_values):\n",
    "    P_D_val = P_to_PD[P]\n",
    "\n",
    "    diag_elements = precomputed_values[P]['diag_elements']\n",
    "    H_A_val = precomputed_values[P]['H_A_val']\n",
    "    H_B_val = precomputed_values[P]['H_B_val']\n",
    "    H_AB_val = precomputed_values[P]['H_AB_val']\n",
    "    \n",
    "    I_AB_val = I_AB(H_A_val, H_B_val, H_AB_val, P_D_val)\n",
    "\n",
    "    return I_AB_val\n",
    "\n",
    "# def calculate_I_AB_BPPM_optimized_wrapper(P, n, P_to_PD, precomputed_values):\n",
    "#     return calculate_I_AB_BPPM_optimized(P, n, P_to_PD, precomputed_values)\n",
    "\n",
    "# Precompute values for faster calculations later\n",
    "# Precompute values for faster calculations later\n",
    "precomputed_values = precompute_values(n, df_P_D.set_index('P')['P_D'].to_dict(), df_matrix_size)\n",
    "\n",
    "num_workers = 8\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    I_AB_BPPM_list_11 = list(executor.map(lambda P: calculate_I_AB_BPPM_optimized(P, n, df_P_D.set_index('P')['P_D'].to_dict(), precomputed_values), P_list))\n",
    "\n",
    "# with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "#     I_AB_BPPM_list_11 = list(executor.map(lambda P: calculate_I_AB_BPPM_optimized_wrapper(P, n, df_P_D.set_index('P')['P_D'].to_dict(), precomputed_values), P_list))\n",
    "\n",
    "plt.plot(P_list, I_AB_BPPM_list_11)\n",
    "plt.xlabel('P')\n",
    "plt.ylabel('I_AB_BPPM')\n",
    "plt.title('Mutual Information vs P for n = 12')\n",
    "plt.grid(color='k', linestyle='-', linewidth=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    number  Time Bin            factorial  \\\n",
      "0        1         1                    1   \n",
      "1        2         3                    2   \n",
      "2        3         7                    6   \n",
      "3        4        14                   24   \n",
      "4        5        26                  120   \n",
      "5        6        46                  720   \n",
      "6        7        75                 5040   \n",
      "7        8       113                40320   \n",
      "8        9       165               362880   \n",
      "9       10       238              3628800   \n",
      "10      11       332             39916800   \n",
      "11      12       459            479001600   \n",
      "12      13       610           6227020800   \n",
      "13      14       791          87178291200   \n",
      "14      15      1002        1307674368000   \n",
      "15      16      1259       20922789888000   \n",
      "16      17      1574      355687428096000   \n",
      "17      18      1947     6402373705728000   \n",
      "18      19      2359   121645100408832000   \n",
      "19      20      2834  2432902008176640000   \n",
      "\n",
      "                                     size  \n",
      "0                                       1  \n",
      "1                                       4  \n",
      "2                                      36  \n",
      "3                                     576  \n",
      "4                                   14400  \n",
      "5                                  518400  \n",
      "6                                25401600  \n",
      "7                              1625702400  \n",
      "8                            131681894400  \n",
      "9                          13168189440000  \n",
      "10                       1593350922240000  \n",
      "11                     229442532802560000  \n",
      "12                   38775788043632640000  \n",
      "13                 7600054456551997440000  \n",
      "14              1710012252724199424000000  \n",
      "15            437763136697395052544000000  \n",
      "16         126513546505547170185216000000  \n",
      "17       40990389067797283140009984000000  \n",
      "18    14797530453474819213543604224000000  \n",
      "19  5919012181389927685417441689600000000  \n"
     ]
    }
   ],
   "source": [
    "print(df_matrix_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: 0.1, P_D_val: None\n"
     ]
    }
   ],
   "source": [
    "print(f\"P: {P}, P_D_val: {P_D_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken by precompute_values: 0.0026974170000357844 seconds\n",
      "Time taken by ThreadPoolExecutor: 0.028892709000047034 seconds\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "# Time the precompute_values function\n",
    "start_time = timeit.default_timer()\n",
    "precomputed_values = precompute_values(n, df_P_D.set_index('P')['P_D'].to_dict(), df_matrix_size)\n",
    "end_time = timeit.default_timer()\n",
    "print(f\"Time taken by precompute_values: {end_time - start_time} seconds\")\n",
    "\n",
    "# Time the ThreadPoolExecutor block\n",
    "start_time = timeit.default_timer()\n",
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    I_AB_BPPM_list_11 = list(executor.map(lambda P: calculate_I_AB_BPPM_optimized(P, n, df_P_D.set_index('P')['P_D'].to_dict(), precomputed_values), P_list))\n",
    "end_time = timeit.default_timer()\n",
    "print(f\"Time taken by ThreadPoolExecutor: {end_time - start_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_I_AB_BPPM(P, n, P_to_PD, df_matrix_size):\n",
    "#     # Extract the corresponding P_D value using the dictionary\n",
    "#     P_D_val = P_to_PD[P]\n",
    "\n",
    "#     diag_elements = compute_diag_elements(n, P_D_val, df_matrix_size)\n",
    "\n",
    "#     H_A_val = H_A(diag_elements)\n",
    "#     H_B_val = H_B(diag_elements)\n",
    "#     H_AB_val = H_AB(diag_elements)\n",
    "#     I_AB_val = I_AB(H_A_val, H_B_val, H_AB_val, P_D_val)\n",
    "\n",
    "#     return I_AB_val\n",
    "\n",
    "# num_workers = 8  # Set to the number of CPU cores available on your system\n",
    "\n",
    "# # Create a dictionary that maps P values to their corresponding P_D values\n",
    "# P_to_PD = dict(zip(df_P_D['P'], df_P_D['P_D']))\n",
    "\n",
    "# with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "#     I_AB_BPPM_list_11 = list(executor.map(lambda P: calculate_I_AB_BPPM(P, n, P_to_PD, df_matrix_size), P_list))\n",
    "\n",
    "\n",
    "# plt.plot(P_list, I_AB_BPPM_list_11)\n",
    "# plt.xlabel('P')\n",
    "# plt.ylabel('I_AB_BPPM')\n",
    "# plt.title('Mutual Information vs P for n = 12')\n",
    "# plt.grid(color='k', linestyle='-', linewidth=0.75)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# def calculate_I_AB_BPPM(P, n, df_P_D, df_matrix_size):\n",
    "#     # Find the row with the desired P value\n",
    "#     row = df_P_D[df_P_D['P'] == P]\n",
    "\n",
    "#     # Extract the corresponding P_D value\n",
    "#     P_D_val = row['P_D'].values[0]\n",
    "\n",
    "#     diag_elements = compute_diag_elements(n, P_D_val, df_matrix_size)\n",
    "\n",
    "#     H_A_val = H_A(diag_elements)\n",
    "#     H_B_val = H_B(diag_elements)\n",
    "#     H_AB_val = H_AB(diag_elements)\n",
    "#     I_AB_val = I_AB(H_A_val, H_B_val, H_AB_val, P_D_val)\n",
    "\n",
    "#     return I_AB_val\n",
    "\n",
    "\n",
    "# n = 12\n",
    "# num_workers = 8  # Set to the number of CPU cores available on your system\n",
    "\n",
    "# with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "#     I_AB_BPPM_list_11 = list(executor.map(lambda P: calculate_I_AB_BPPM(P, n, df_P_D, df_matrix_size), P_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_AB_list = []\n",
    "\n",
    "P_list = np.linspace(1e-6, 0.1, 101)\n",
    "\n",
    "\n",
    "for P in P_list:\n",
    "    n = 11\n",
    "    N_n = compute_N(n)\n",
    "    P_D_val = P_D(n, P, 0, 0, 0, N_n)\n",
    "\n",
    "    diag_elements = compute_diag_elements(n, P_D_val)\n",
    "\n",
    "    H_A_val = H_A(diag_elements)\n",
    "    H_B_val = H_B(diag_elements)\n",
    "    H_AB_val = H_AB(diag_elements)\n",
    "    I_AB_val = I_AB(H_A_val, H_B_val, H_AB_val, P_D_val)\n",
    "    I_AB_list.append(I_AB_val)\n",
    "\n",
    "# for P in P_list:\n",
    "#     n = 11\n",
    "#     N_n = compute_N(n)\n",
    "#     P_D_val = P_D(n, P, 0, 0, 0, N_n)\n",
    "\n",
    "#     P_AB_val = P_AB(n, P_D_val)\n",
    "#     H_A_val = entropy(P_AB_val.diagonal())\n",
    "#     H_B_val = entropy(P_AB_val.diagonal())\n",
    "#     H_AB_val = entropy(P_AB_val.diagonal())\n",
    "#     I_AB_val = I_AB(H_A_val, H_B_val, H_AB_val, P_D_val)\n",
    "#     I_AB_list.append(I_AB_val)\n",
    "\n",
    "    # Rest of the loop\n",
    "\n",
    "\n",
    "# for P in P_list:\n",
    "#     n = 10\n",
    "#     N_n = compute_N(n)\n",
    "#     P_D_val = P_D(n, P, 0, 0, 0, N_n)\n",
    "\n",
    "#     P_AB_val = P_AB(n, P_D_val)\n",
    "\n",
    "#     H_A_val = entropy(P_AB_val.diagonal())\n",
    "#     H_B_val = entropy(P_AB_val.diagonal())\n",
    "#     H_AB_val = entropy(P_AB_val.diagonal())\n",
    "#     I_AB_val = I_AB(H_A_val, H_B_val, H_AB_val, P_D_val)\n",
    "#     I_AB_list.append(I_AB_val)\n",
    "\n",
    "plt.plot(P_list, I_AB_list, label='I_AB renormalized', linewidth=3, alpha=1)\n",
    "\n",
    "plt.xlabel('Probability, P')\n",
    "plt.ylabel('Mutual Information, I_AB')\n",
    "\n",
    "plt.grid(color='k', linestyle='-', linewidth=0.75)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "from pyparsing import python_style_comment\n",
    "from itertools import islice\n",
    "import scipy.sparse as sps\n",
    "from scipy.sparse import diags\n",
    "from functools import lru_cache\n",
    "from multiprocessing import Pool\n",
    "from scipy.special import comb as combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_cache = {}\n",
    "#we need combination to calculate Loss_Disitribution, Add_Distribution, P_err\n",
    "# define a separate function for computing the sequence of terms used in N\n",
    "# def combination(n, r):\n",
    "#     # if r > n:\n",
    "#     #     return 0\n",
    "#     # else:\n",
    "#     return math.factorial((int(n))) / (math.factorial((int(n-r))) * math.factorial((int(r))))\n",
    "\n",
    "# def combination(n, r):\n",
    "#     if (n, r) in comb_cache:\n",
    "#         return comb_cache[(n, r)]\n",
    "#     else:\n",
    "#         comb = math.factorial(n) // (math.factorial(n-r) * math.factorial(r))\n",
    "#         comb_cache[(n, r)] = comb\n",
    "#         return comb\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def combination(n, r):\n",
    "    if r > n:\n",
    "        return 0\n",
    "    elif r == 0 or r == n:\n",
    "        return 1\n",
    "    else:\n",
    "        return combination(n-1, r-1) + combination(n-1, r)\n",
    "    \n",
    "# @lru_cache(maxsize=None)\n",
    "# def compute_N(n):\n",
    "#   def agen(): # generator of terms\n",
    "#       aset, sset, k = set(), set(), 0\n",
    "#       while True:\n",
    "#           k += 1\n",
    "#           while any(k+an in sset for an in aset): k += 1\n",
    "#           yield k; sset.update(k+an for an in aset); aset.add(k)\n",
    "#   a = list(islice(agen(), 100))\n",
    "#   photon = list(map(lambda v: v-1, a))\n",
    "#   compute_N= [sum(photon[:i]) for i in range(1,len(photon)+1)]\n",
    "#   return compute_N[n]\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def compute_N(n):\n",
    "    aset, sset, k = set(), set(), 0\n",
    "    gen_exp = (k for _ in range(100) if (k := next(i for i in range(k+1, 2*k+2) if i not in {k+an for an in aset})))\n",
    "    photon = [v-1 for v in islice(gen_exp, 100)]\n",
    "    compute_N_result = [sum(photon[:i]) for i in range(1, len(photon)+1)]\n",
    "    return compute_N_result[n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.special import comb as combination\n",
    "from scipy.sparse import diags\n",
    "import scipy.sparse as sps\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.special import comb\n",
    "\n",
    "comb_n_cache = {}\n",
    "comb_n_M_minus_n_cache = {}\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def compute_N(n):\n",
    "    aset, sset, k = set(), set(), 0\n",
    "    gen_exp = (k for _ in range(100) if (k := next(i for i in range(k+1, 2*k+2) if i not in {k+an for an in aset})))\n",
    "    photon = [v-1 for v in islice(gen_exp, 100)]\n",
    "    compute_N_result = [sum(photon[:i]) for i in range(1, len(photon)+1)]\n",
    "    return compute_N_result[n]\n",
    "\n",
    "# @lru_cache(maxsize=None)\n",
    "# def combination(n, r):\n",
    "#     if r > n:\n",
    "#         return 0\n",
    "#     elif r == 0 or r == n:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return combination(n-1, r-1) + combination(n-1, r)\n",
    "    \n",
    "# def vectorized_combination(n, r):\n",
    "#     n, r = np.broadcast_arrays(n, r)\n",
    "#     result = np.zeros_like(n)\n",
    "#     mask = (r <= n) & (r >= 0)\n",
    "#     result[mask] = np.array([math.comb(int(nv), int(rv)) for nv, rv in zip(n[mask], r[mask])])\n",
    "#     return result\n",
    "\n",
    "# def vectorized_combination(n, r):\n",
    "#     n, r = np.broadcast_arrays(n, r)\n",
    "#     result = np.zeros_like(n)\n",
    "#     mask = (r <= n) & (r >= 0)\n",
    "#     result[mask] = np.array([comb(int(nv), int(rv), exact=True) for nv, rv in zip(n[mask], r[mask])])\n",
    "#     return result\n",
    "\n",
    "from scipy.special import gammaln\n",
    "\n",
    "def vectorized_combination(n, r):\n",
    "    n, r = np.broadcast_arrays(n, r)\n",
    "    result = np.zeros_like(n, dtype=np.float64)\n",
    "    mask = (r <= n) & (r >= 0)\n",
    "    result[mask] = np.exp(gammaln(n[mask] + 1) - gammaln(r[mask] + 1) - gammaln(n[mask] - r[mask] + 1))\n",
    "    return result\n",
    "\n",
    "\n",
    "# def Loss_Distribute(n, P_l, l):\n",
    "#     comb_n = combination(n, l)\n",
    "#     return comb_n * (P_l)**l * (1 - P_l)**(n - l)\n",
    "\n",
    "# def Add_Distribute(n, P_a, a, N_n):\n",
    "#     M_minus_n = N_n - n\n",
    "#     comb_Nn_Mn = combination(N_n + M_minus_n, a)\n",
    "#     return comb_Nn_Mn * (P_a)**a * (1 - P_a)**(M_minus_n - a)\n",
    "\n",
    "# def P_err(n, P_l, P_a, l, a, N_n):\n",
    "#     return Loss_Distribute(n, P_l, l) * Add_Distribute(n, P_a, a, N_n)\n",
    "\n",
    "# def P_err(n, P_l, P_a, l, a, N_n):\n",
    "#     Loss_Distribute = combination(n, l) * (P_l)**l * (1 - P_l)**(n - l)\n",
    "#     Add_Distribute = combination(N_n + N_n - n, a) * (P_a)**a * (1 - P_a)**(N_n - n - a)\n",
    "#     return Loss_Distribute * Add_Distribute\n",
    "\n",
    "def P_err(n, P_l, P_a, l, a, N_n):\n",
    "    Loss_Distribute = vectorized_combination(n, l) * (P_l)**l * (1 - P_l)**(n - l)\n",
    "    Add_Distribute = vectorized_combination(N_n + N_n - n, a) * (P_a)**a * (1 - P_a)**(N_n - n - a)\n",
    "    return Loss_Distribute * Add_Distribute\n",
    "\n",
    "# def P_Success0(n, P_l, P_a, l, a, N_n):\n",
    "#     return P_err(n, P_l, P_a, 0, 0, N_n)\n",
    "\n",
    "# def P_Success1(n, P_l, P_a, l, a, N_n):\n",
    "#     P0 = P_Success0(n, P_l, P_a, l, a, N_n)\n",
    "#     P1 = P_err(n, P_l, P_a, 0, 1, N_n) + P_err(n, P_l, P_a, 1, 0, N_n)\n",
    "#     return P0 + P1\n",
    "\n",
    "# def P_D(n, P_l, P_a, l, a, N_n):\n",
    "#     return 1 - P_Success1(n, P_l, P_a, l, a, N_n)\n",
    "\n",
    "# def P_D(n, P_l, P_a, l, a, N_n): # for at most 1 error \n",
    "#     return 1 - (P_err(n, P_l, P_a, 0, 0, N_n) + P_err(n, P_l, P_a, 0, 1, N_n) + P_err(n, P_l, P_a, 1, 0, N_n))\n",
    "\n",
    "def P_D(pd, n, l, a, N_n):\n",
    "    N_A = N_n[:, a]\n",
    "    N_l = N_A[l]\n",
    "    return N_l * (1 - pd) / n\n",
    "\n",
    "\n",
    "# def I_AB(H_A, H_B, H_AB, P_D):\n",
    "#     if np.isnan(H_AB):\n",
    "#         return 0\n",
    "#     else:\n",
    "#         return ((H_A + H_B - H_AB))*(1-P_D)\n",
    "\n",
    "def I_AB(H_A, H_B, H_AB, P_D):\n",
    "    return np.where(np.isnan(H_AB), 0, H_A + H_B - H_AB)\n",
    "\n",
    "\n",
    "# def P_AB(n, P_D):\n",
    "#     factorial_n = round(math.gamma(n + 1))\n",
    "#     diag_data = (1 / factorial_n) * (1 - P_D) * np.ones(factorial_n)\n",
    "#     matrix = sps.dia_matrix((diag_data, 0), shape=(factorial_n, factorial_n))\n",
    "#     return matrix\n",
    "\n",
    "def P_AB(n, P_D):\n",
    "    factorial_n = round(math.gamma(n + 1))\n",
    "    diag_data = (1 / factorial_n) * (1 - P_D) * np.ones(factorial_n)\n",
    "    matrix = np.diag(diag_data)\n",
    "    return matrix\n",
    "\n",
    "\n",
    "# def P_AB(n, P_D):\n",
    "#     factorial_n = round(math.gamma(n + 1))\n",
    "#     diag_data = (1 / factorial_n) * (1 - P_D) * np.ones((P_D.shape[0], factorial_n))\n",
    "#     matrix = sps.dia_matrix((diag_data, np.zeros(P_D.shape[0])), shape=(P_D.shape[0], factorial_n, factorial_n))\n",
    "#     return matrix\n",
    "\n",
    "# def P_AB(n, P_D):\n",
    "#     factorial_n = round(math.gamma(n + 1))\n",
    "#     diag_data = (1 / factorial_n) * (1 - P_D) * np.ones((P_D.shape[0], factorial_n))\n",
    "#     matrix = sps.dia_matrix((diag_data, np.zeros(diag_data.shape[1])), shape=(diag_data.shape[0], diag_data.shape[1], diag_data.shape[1]))\n",
    "#     return matrix\n",
    "\n",
    "# def P_AB(n, P_D):\n",
    "#     factorial_n = round(math.gamma(n + 1))\n",
    "#     diag_data = (1 / factorial_n) * (1 - P_D) * np.ones((P_D.shape[0], factorial_n))\n",
    "#     matrix = sps.dia_matrix((diag_data, [0]), shape=(diag_data.shape[0], diag_data.shape[1]))\n",
    "# #     return matrix\n",
    "\n",
    "# def P_AB(n, P_D):\n",
    "#     P_D = np.asarray(P_D)\n",
    "#     factorial_n = round(math.gamma(n + 1))\n",
    "#     diag_data = (1 / factorial_n) * (1 - P_D) * np.ones((P_D.shape[0], factorial_n))\n",
    "#     offsets = np.zeros((1,), dtype=int)\n",
    "#     matrix = sps.dia_matrix((diag_data, offsets), shape=(diag_data.shape[0], diag_data.shape[1]))\n",
    "#     return matrix.toarray()\n",
    "\n",
    "# def P_AB(n, P_D):\n",
    "#     P_D = np.asarray(P_D)\n",
    "#     factorial_n = round(math.gamma(n + 1))\n",
    "#     diag_data = np.array([(1 / factorial_n) * (1 - p) * np.ones(factorial_n) for p in P_D])\n",
    "#     offsets = np.zeros((1,), dtype=int)\n",
    "#     matrices = [sps.dia_matrix((data, offsets), shape=(factorial_n, factorial_n)).toarray() for data in diag_data]\n",
    "#     return np.stack(matrices)\n",
    "\n",
    "def entropy(P):\n",
    "    P_non_zero = np.where(P == 0, 1, P)\n",
    "    H = -np.sum(P * np.log2(P_non_zero))\n",
    "    return H\n",
    "\n",
    "def H_A(P_AB):\n",
    "    P_A = P_AB.diagonal()\n",
    "    return -np.sum(P_A * np.log2(np.where(P_A == 0, 1, P_A)))\n",
    "\n",
    "def H_B(P_AB):\n",
    "    P_B = P_AB.diagonal()\n",
    "    return -np.sum(P_B * np.log2(np.where(P_B == 0, 1, P_B)))\n",
    "\n",
    "# def H_AB(P_AB):\n",
    "#     P_AB = P_AB.diagonal()\n",
    "#     P_AB = np.where(P_AB == 0, 1e-9, P_AB)  # replace zero values with 1e-9\n",
    "#     return -(P_AB * np.log2(P_AB)).sum()\n",
    "\n",
    "def H_AB(P_AB):\n",
    "    P_AB_non_zero = np.where(P_AB == 0, 1, P_AB)\n",
    "    H = -np.sum(P_AB * np.log2(P_AB_non_zero))\n",
    "    return H\n",
    "\n",
    "\n",
    "# Rest of the code remains the same\n",
    "\n",
    "\n",
    "# def compute_mutual_information(P_list, n, N_n):\n",
    "#     P_l = P_list[:, np.newaxis, np.newaxis, np.newaxis, np.newaxis]\n",
    "#     P_a = np.zeros_like(P_l)\n",
    "#     l, a = np.meshgrid(np.arange(n + 1), np.arange(N_n - n + 1), indexing='ij')\n",
    "\n",
    "#     P_err_val = P_err(n, P_l, P_a, l, a, N_n)\n",
    "#     P_D_val = P_D(n, P_l, P_a, l, a, N_n)\n",
    "\n",
    "#     P_AB_val = P_AB(n, P_D_val)\n",
    "#     H_A_val = entropy(P_AB_val.diagonal())\n",
    "#     H_B_val = entropy(P_AB_val.diagonal())\n",
    "#     H_AB_val = entropy(P_AB_val.diagonal())\n",
    "#     I_AB_val = I_AB(H_A_val, H_B_val, H_AB_val, P_D_val)\n",
    "\n",
    "#     return I_AB_val\n",
    "\n",
    "# def compute_mutual_information(P_list, n, N_n):\n",
    "#     P_l = P_list[:, np.newaxis, np.newaxis]\n",
    "#     P_a = np.zeros_like(P_l)\n",
    "#     l, a = np.meshgrid(np.arange(n + 1), np.arange(N_n - n + 1), indexing='ij')\n",
    "    \n",
    "#     P_err_val = P_err(n, P_l, P_a, l, a, N_n)\n",
    "#     P_D_val = P_D(n, P_l, P_a, l, a, N_n)\n",
    "\n",
    "#     P_AB_val = P_AB(n, P_D_val)\n",
    "#     H_A_val = entropy(P_AB_val.diagonal())\n",
    "#     H_B_val = entropy(P_AB_val.diagonal())\n",
    "#     H_AB_val = entropy(P_AB_val.diagonal())\n",
    "#     I_AB_val = I_AB(H_A_val, H_B_val, H_AB_val, P_D_val)\n",
    "\n",
    "# def compute_mutual_information(P_list, n, N_n):\n",
    "#     P_l = P_list[:, np.newaxis, np.newaxis]\n",
    "#     P_a = np.zeros_like(P_l)\n",
    "#     l, a = np.meshgrid(np.arange(n + 1), np.arange(N_n - n + 1), indexing='ij')\n",
    "    \n",
    "#     P_err_val = P_err(n, P_l, P_a, l, a, N_n)\n",
    "#     P_D_val = P_D(n, P_l, P_a, l, a, N_n)\n",
    "\n",
    "#     P_AB_val = np.array([P_AB(n, pd) for pd in P_D_val])\n",
    "#     # H_A_val = np.array([entropy(pab.diagonal()) for pab in P_AB_val])\n",
    "#     # H_B_val = np.array([entropy(pab.diagonal()) for pab in P_AB_val])\n",
    "#     # H_A_val = np.array([entropy(np.diagonal(pab)) for pab in P_AB_val])\n",
    "#     # H_B_val = np.array([entropy(np.diagonal(pab)) for pab in P_AB_val])\n",
    "#     H_A_val = np.array([entropy(np.diagonal(pab)) if pab.ndim >= 2 else entropy(pab) for pab in P_AB_val])\n",
    "#     H_B_val = np.array([entropy(np.diagonal(pab)) if pab.ndim >= 2 else entropy(pab) for pab in P_AB_val])\n",
    "\n",
    "#     # H_AB_val = np.array([entropy(pab) for pab in P_AB_val])  # modified this line\n",
    "#     H_AB_val = np.array([-np.sum(pab * np.where(pab != 0, np.log2(pab), 0)) for pab in P_AB_val])\n",
    "\n",
    "#     I_AB_val = I_AB(H_A_val, H_B_val, H_AB_val, P_D_val)\n",
    "\n",
    "#     return I_AB_val\n",
    "\n",
    "def compute_mutual_information(P_list, n, l, a, N_n):\n",
    "    P_D_val = np.array([P_D(pd, n, l, a, N_n) for pd in P_list])\n",
    "    P_AB_val = np.array([P_AB(n, pd) for pd in P_D_val])\n",
    "    H_A_val = np.array([entropy(np.diagonal(pab)) if pab.ndim >= 2 else entropy(pab) for pab in P_AB_val])\n",
    "    H_AB_val = np.array([entropy(pab) for pab in P_AB_val])\n",
    "    I_AB = H_A_val + H_A_val - H_AB_val\n",
    "    return I_AB\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     return I_AB_val\n",
    "\n",
    "# I_AB_list = []\n",
    "\n",
    "P_list = np.linspace(1e-6, 0.1, 101)\n",
    "\n",
    "n = 9\n",
    "\n",
    "N_n = compute_N(n)\n",
    "\n",
    "# I_AB_val = compute_mutual_information(P_list, n, N_n)\n",
    "# I_AB_list = I_AB_val.reshape(-1).tolist()\n",
    "\n",
    "# for P in P_list:\n",
    "#     n = 12\n",
    "#     N_n = compute_N(n)\n",
    "#     P_D_val = P_D(n, P, 0, 0, 0, N_n)\n",
    "\n",
    "#     P_AB_val = P_AB(n, P_D_val)\n",
    "\n",
    "#     # H_A_val = H_A(P_AB_val)\n",
    "#     # H_B_val = H_B(P_AB_val)\n",
    "#     # H_AB_val = H_AB(P_AB_val)\n",
    "#     # I_AB_val = I_AB(H_A_val, H_B_val, H_AB_val, P_D_val)\n",
    "#     # I_AB_list.append(I_AB_val)\n",
    "#     H_A_val = entropy(P_AB_val.diagonal())\n",
    "#     H_B_val = entropy(P_AB_val.diagonal())\n",
    "#     H_AB_val = entropy(P_AB_val.diagonal())\n",
    "#     I_AB_val = I_AB(H_A_val, H_B_val, H_AB_val, P_D_val)\n",
    "#     I_AB_list.append(I_AB_val)\n",
    "\n",
    "l= 0\n",
    "a= 0\n",
    "I_AB_list = compute_mutual_information(P_list, n, l, a, N_n)\n",
    "\n",
    "\n",
    "plt.plot(P_list, I_AB_list, label='I_AB renormalized', linewidth=3, alpha=1)\n",
    "\n",
    "plt.xlabel('Probability, P')\n",
    "plt.ylabel('Mutual Information, I_AB')\n",
    "\n",
    "plt.grid(color='k', linestyle='-', linewidth=0.75)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"H_A_val:\", H_A_val)\n",
    "print(\"H_B_val:\", H_B_val)\n",
    "print(\"H_AB_val:\", H_AB_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_AB_list = compute_mutual_information(P_list, n, N_n)\n",
    "\n",
    "plt.plot(P_list, I_AB_list)\n",
    "plt.xlabel(\"P_l\")\n",
    "plt.ylabel(\"I_AB\")\n",
    "plt.title(\"I_AB vs P_l\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_AB(5, P_D(5, 0, 0, 0, 0, compute_N(5))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_AB_list = []\n",
    "\n",
    "P_list = np.linspace(1e-6,0.1,101)\n",
    "\n",
    "for P in P_list:\n",
    "    n = 11\n",
    "    N_n = compute_N(n)\n",
    "    P_D_val = P_D(n, P, 0, 0, 0, N_n)\n",
    "\n",
    "    P_AB_val = P_AB(n, P_D_val)\n",
    "\n",
    "    H_A_val = H_A(P_AB_val)\n",
    "    H_B_val = H_B(P_AB_val)\n",
    "    H_AB_val = H_AB(P_AB_val)\n",
    "    I_AB_val = I_AB(H_A_val, H_B_val, H_AB_val, P_D_val)\n",
    "    I_AB_list.append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_AB(n, P, P_D):\n",
    "    factorial_n = math.factorial(n)\n",
    "    diag_data = (1/factorial_n) * (1-P_D) * np.ones(factorial_n)\n",
    "    matrix = sps.dia_matrix((diag_data, 0), shape=(factorial_n, factorial_n))\n",
    "    return matrix\n",
    "\n",
    "def H_A(P_AB):\n",
    "    P_A = P_AB.diagonal()\n",
    "    H_a = np.sum(-P_A * np.log2(np.where(P_A == 0, 1, P_A)))\n",
    "    return H_a\n",
    "\n",
    "def H_B(P_AB):\n",
    "    P_B = P_AB.diagonal()\n",
    "    H_b = np.sum(-P_B * np.log2(np.where(P_B == 0, 1, P_B)))\n",
    "    return H_b\n",
    "\n",
    "def H_AB(P_AB):\n",
    "    P_AB = P_AB.diagonal()\n",
    "    P_AB = np.where(P_AB == 0, 1e-9, P_AB)  # replace zero values with 1e-9\n",
    "    H = -(P_AB * np.log2(P_AB)).sum()\n",
    "    return H\n",
    "\n",
    "I_AB_list = []\n",
    "\n",
    "P_list = np.linspace(1e-6,0.1,101)\n",
    "\n",
    "for P in P_list:\n",
    "  n = 11\n",
    "  N_n = compute_N(n) \n",
    "  P_D_val = P_D(n,P, 0,0,0)\n",
    "  \n",
    "  P_AB_val = P_AB(n, P, P_D_val)\n",
    "  \n",
    "  H_A_val = H_A(P_AB_val)\n",
    "  H_B_val = H_B(P_AB_val)\n",
    "  H_AB_val = H_AB(P_AB_val)\n",
    "  I_AB_val = I_AB(H_A_val, H_B_val, H_AB_val, P_D_val)\n",
    "  I_AB_normalized_val = I_AB(H_A_val, H_B_val, H_AB_val, P_D_val) / I_AB(H_A_val, H_B_val, H_AB_val, 0)\n",
    "  I_AB_list.append(I_AB_normalized_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(P_list, I_AB_list, label='I_AB_BPPM renormalized', linewidth=3, alpha=1)\n",
    "\n",
    "# Add axis labels and a title\n",
    "plt.xlabel('Probability, P')\n",
    "plt.ylabel('Muutal Information, I_AB')\n",
    "plt.title('Mutual Information of BPPM (n = 5), PPM (M = 5) and  \\n General Protocol (n =2, 3) vs. Probability 0 \\u2264 P \\u2264 0.1', fontsize='x-large')\n",
    "\n",
    "plt.grid(color='k', linestyle='-', linewidth=0.75)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it takes more than a minute to run the iteration for n = 11.\n",
    "\n",
    "Since we only use the diagonal elements of the matrix, we don't need to compute the entire matrix. \n",
    "\n",
    "Instead, we can calculate only the diagonal elements directly and avoid creating the matrix altogether. This will save both memory and computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_M(M):\n",
    "  return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compute_G_n(n_General):\n",
    "    return n_General\n",
    "\n",
    "def compute_T_General(n_General, M):\n",
    "  T_General = compute_M(M) * n_General\n",
    "  return T_General\n",
    "\n",
    "#we need combination to calculate Loss_Disitribution, Add_Distribution, P_err\n",
    "# define a separate function for computing the sequence of terms used in N\n",
    "def combination_General(T_General, n_General):\n",
    "    # if r > n:\n",
    "    #     return 0\n",
    "    # else:\n",
    "    # return math.factorial((int(T_General))) / (math.factorial((int(T_General-n_General))) * math.factorial((int(n_General))))\n",
    "    return math.factorial(((T_General))) / (math.factorial(((T_General-n_General))) * math.factorial(((n_General))))\n",
    "\n",
    "# We need LossDisitribution, AddDistribution, Perr to calculate PSuccess0, PSuccess1, PSuccess2 and so on\n",
    "# define a separate function for computing the loss distribution\n",
    "\n",
    "def Loss_Distribute_General(n_General, P_l, l):\n",
    "    # if P_l == 0:\n",
    "    #     return 1\n",
    "    # else:\n",
    "      return combination(n_General, l) * (P_l)**l * (1 - P_l)**(n_General - l)\n",
    "\n",
    "def Add_Distribute_General(n_General, P_a, a):\n",
    "    \n",
    "    T_General = compute_T_General(n_General)\n",
    "    # if P_a == 0:\n",
    "    #     return 1\n",
    "    # else:\n",
    "    return combination(T_General - n_General, a) * (P_a)**a * (1 - P_a)**(T_General - n_General - a)\n",
    "\n",
    "# define a separate function for computing the probability of error\n",
    "def P_err(n_General, P_l, P_a,l,a):\n",
    "  return Loss_Distribute(n_General,P_l,l) * Add_Distribute(n_General,P_a, a)\n",
    "\n",
    "def P_Success_General(n_General,P_l,P_a,l,a):\n",
    "  return P_err(n_General,P_l, P_a, l=0, a=0) \n",
    "\n",
    "# Perr[l = 0, a = 0, n = 1, N = M, Ploss, Padd] from mathematica\n",
    "\n",
    "def P_D_General(n_General,P_l,P_a, l=0,a=0):\n",
    "  return 1 - P_Success_General(n_General,P_l,P_a, l=0, a=0)\n",
    "\n",
    "def P_A_General(P_AB_General, P_D_General):\n",
    "    if P_D == 1:\n",
    "        return [1 for row in P_AB_General]\n",
    "    else:\n",
    "        return [sum(row) for row in P_AB_General] # 1/(1-P_D_OOK)*\n",
    "\n",
    "# sum over the elements in columns in the probability matrix P_AB\n",
    "def P_B_General(P_AB_General, P_D_General):\n",
    "    if P_D == 1:\n",
    "        return [1 for col in zip(*P_AB_General)]\n",
    "    else:\n",
    "        return [sum(col) for col in zip(*P_AB_General)]\n",
    "\n",
    "def I_AB_General(H_A_General, H_B_General, H_AB_General, P_D_General):\n",
    "    if np.isnan(H_AB_General):\n",
    "        return 0\n",
    "    else:\n",
    "        return ((H_A_General + H_B_General - H_AB_General)) * (1-P_D_General)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_AB_diag_General(M, n_General):\n",
    "    T_General = compute_T_General(n_General, M)\n",
    "    diag_data = np.ones(int(combination(T_General, n_General))) / combination(T_General, n_General)\n",
    "    matrix = sps.dia_matrix((diag_data, 0), shape=(diag_data.size, diag_data.size))\n",
    "    return matrix\n",
    "    \n",
    "def H_A_General(P_A_General):\n",
    "    P_A_General_diag = P_A_General.diagonal()\n",
    "    H_a_General = np.sum(-P_A_General_diag * np.log2(np.where(P_A_General_diag == 0, 1, P_A_General_diag)))\n",
    "    return H_a_General\n",
    "\n",
    "def H_B_General(P_B_General):\n",
    "    P_B_General_diag = P_B_General.diagonal()\n",
    "    H_b_General = np.sum(-P_B_General_diag * np.log2(np.where(P_B_General_diag == 0, 1, P_B_General_diag)))\n",
    "    return H_b_General\n",
    "\n",
    "def H_AB_General(P_AB_General):\n",
    "    P_AB_General_diag = P_AB_General.diagonal()\n",
    "    P_AB_General_diag = np.where(P_AB_General_diag == 0, 1e-9, P_AB_General_diag)  # replace zero values with 1e-9\n",
    "    H_General = -(P_AB_General_diag * np.log2(P_AB_General_diag)).sum()\n",
    "    return H_General\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_AB_General_n2_list_10 = []\n",
    "I_AB_General_n3_list_10 = []\n",
    "\n",
    "P_list = np.linspace(1e-6,0.1,101)\n",
    "\n",
    "for P in P_list:\n",
    "  M = 5\n",
    "  compute_M(M)\n",
    "  n_General = Compute_G_n(2)\n",
    "  T_General = compute_T_General(n_General, M)\n",
    "\n",
    "  P_D_General_val = P_D_General(n_General, P, 0, l=0, a=0)\n",
    "\n",
    "  P_AB_General_diag_val = P_AB_diag_General(M, n_General)\n",
    "  P_AB_General_diag_val = P_AB_General_diag_val.todia()\n",
    "  P_AB_General_diag_val.setdiag(np.where(P_AB_General_diag_val.diagonal() <= 0, 1e-9, P_AB_General_diag_val.diagonal()))\n",
    "  H_A_General_val = H_A_General(P_AB_General_diag_val)\n",
    "  H_B_General_val = H_B_General(P_AB_General_diag_val)\n",
    "  H_AB_General_val = H_AB_General(P_AB_General_diag_val)\n",
    "  I_AB_General_val = I_AB_General(H_A_General_val, H_B_General_val, H_AB_General_val, P_D_General_val)\n",
    "  \n",
    "  I_AB_General_n2_normalized_val =  I_AB_General(H_A_General_val, H_B_General_val, H_AB_General_val, P_D_General_val) / I_AB_General(H_A_General_val, H_B_General_val, H_AB_General_val, 0)\n",
    "  I_AB_General_n2_list_10.append(I_AB_General_n2_normalized_val)\n",
    "\n",
    "  n_General = Compute_G_n(3)\n",
    "  T_General = compute_T_General(n_General, M)\n",
    "\n",
    "  P_D_General_val = P_D_General(n_General, P, 0, l=0, a=0)\n",
    "\n",
    "  P_AB_General_diag_val = P_AB_diag_General(M, n_General)\n",
    "  P_AB_General_diag_val = P_AB_General_diag_val.todia()\n",
    "  P_AB_General_diag_val.setdiag(np.where(P_AB_General_diag_val.diagonal() <= 0, 1e-9, P_AB_General_diag_val.diagonal()))\n",
    "\n",
    "  H_A_General_val = H_A_General(P_AB_General_diag_val)\n",
    "  H_B_General_val = H_B_General(P_AB_General_diag_val)\n",
    "  H_AB_General_val = H_AB_General(P_AB_General_diag_val)\n",
    "  I_AB_General_val = I_AB_General(H_A_General_val, H_B_General_val, H_AB_General_val, P_D_General_val)\n",
    "  \n",
    "  I_AB_General_n3_normalized_val = I_AB_General(H_A_General_val, H_B_General_val, H_AB_General_val, P_D_General_val) / I_AB_General(H_A_General_val, H_B_General_val, H_AB_General_val, 0)\n",
    "  I_AB_General_n3_list_10.append(I_AB_General_n3_normalized_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_AB_diag(n, P, P_D):\n",
    "    factorial_n = math.factorial(n)\n",
    "    diag_data = (1/factorial_n) * (1-P_D) * np.ones(factorial_n)\n",
    "    return diag_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H_A(P_A):\n",
    "    H_a = np.sum(-P_A * np.log2(np.where(P_A == 0, 1, P_A)))\n",
    "    return H_a\n",
    "\n",
    "def H_B(P_B):\n",
    "    H_b = np.sum(-P_B * np.log2(np.where(P_B == 0, 1, P_B)))\n",
    "    return H_b\n",
    "\n",
    "def H_AB(P_AB):\n",
    "    P_AB = np.where(P_AB == 0, 1e-9, P_AB)  # replace zero values with 1e-9\n",
    "    H = -(P_AB * np.log2(P_AB)).sum()\n",
    "    return H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I_AB_list = []\n",
    "\n",
    "# P_list = np.linspace(1e-6, 0.999999, 101)\n",
    "\n",
    "# for P in P_list:\n",
    "#     n = 12\n",
    "#     N_n = compute_N(n) \n",
    "#     P_D_val = P_D(n, P, 0, 0, 0)\n",
    "\n",
    "#     P_AB_diag_val = P_AB_diag(n, P, P_D_val)\n",
    "\n",
    "#     H_A_val = H_A(P_AB_diag_val)\n",
    "#     H_B_val = H_B(P_AB_diag_val)\n",
    "#     H_AB_val = H_AB(P_AB_diag_val)\n",
    "#     I_AB_val = I_AB(H_A_val, H_B_val, H_AB_val, P_D_val)\n",
    "#     I_AB_list.append(I_AB_val)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, it can not run faster as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_AB(5, 0, P_D(5,0, 0,0,0)) *(120) * (1/1-P_D(5,0, 0,0,0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_M(M):\n",
    "  return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compute_G_n(n_General):\n",
    "    return n_General\n",
    "\n",
    "def compute_T_General(n_General, M):\n",
    "  T_General = compute_M(M) * n_General\n",
    "  return T_General\n",
    "\n",
    "#we need combination to calculate Loss_Disitribution, Add_Distribution, P_err\n",
    "# define a separate function for computing the sequence of terms used in N\n",
    "def combination_General(T_General, n_General):\n",
    "    # if r > n:\n",
    "    #     return 0\n",
    "    # else:\n",
    "    # return math.factorial((int(T_General))) / (math.factorial((int(T_General-n_General))) * math.factorial((int(n_General))))\n",
    "    return math.factorial(((T_General))) / (math.factorial(((T_General-n_General))) * math.factorial(((n_General))))\n",
    "\n",
    "# We need LossDisitribution, AddDistribution, Perr to calculate PSuccess0, PSuccess1, PSuccess2 and so on\n",
    "# define a separate function for computing the loss distribution\n",
    "\n",
    "def Loss_Distribute_General(n_General, P_l, l):\n",
    "    # if P_l == 0:\n",
    "    #     return 1\n",
    "    # else:\n",
    "      return combination(n_General, l) * (P_l)**l * (1 - P_l)**(n_General - l)\n",
    "\n",
    "def Add_Distribute_General(n_General, P_a, a):\n",
    "    \n",
    "    T_General = compute_T_General(n_General)\n",
    "    # if P_a == 0:\n",
    "    #     return 1\n",
    "    # else:\n",
    "    return combination(T_General - n_General, a) * (P_a)**a * (1 - P_a)**(T_General - n_General - a)\n",
    "\n",
    "# define a separate function for computing the probability of error\n",
    "def P_err(n_General, P_l, P_a,l,a):\n",
    "  return Loss_Distribute(n_General,P_l,l) * Add_Distribute(n_General,P_a, a)\n",
    "\n",
    "def P_Success_General(n_General,P_l,P_a,l,a):\n",
    "  return P_err(n_General,P_l, P_a, l=0, a=0) \n",
    "\n",
    "# Perr[l = 0, a = 0, n = 1, N = M, Ploss, Padd] from mathematica\n",
    "\n",
    "def P_D_General(n_General,P_l,P_a, l=0,a=0):\n",
    "  return 1 - P_Success_General(n_General,P_l,P_a, l=0, a=0)\n",
    "\n",
    "def P_A_General(P_AB_General, P_D_General):\n",
    "    if P_D == 1:\n",
    "        return [1 for row in P_AB_General]\n",
    "    else:\n",
    "        return [sum(row) for row in P_AB_General] # 1/(1-P_D_OOK)*\n",
    "\n",
    "# sum over the elements in columns in the probability matrix P_AB\n",
    "def P_B_General(P_AB_General, P_D_General):\n",
    "    if P_D == 1:\n",
    "        return [1 for col in zip(*P_AB_General)]\n",
    "    else:\n",
    "        return [sum(col) for col in zip(*P_AB_General)]\n",
    "\n",
    "def I_AB_General(H_A_General, H_B_General, H_AB_General, P_D_General):\n",
    "    if np.isnan(H_AB_General):\n",
    "        return 0\n",
    "    else:\n",
    "        return ((H_A_General + H_B_General - H_AB_General)) * (1-P_D_General)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_AB_diag_General(M, n_General):\n",
    "    T_General = compute_T_General(n_General, M)\n",
    "    diag_data = np.ones(int(combination(T_General, n_General))) / combination(T_General, n_General)\n",
    "    return diag_data\n",
    "\n",
    "\n",
    "def H_A_General(P_A_General):\n",
    "    H_a_General = np.sum(-P_A_General * np.log2(np.where(P_A_General == 0, 1, P_A_General)))\n",
    "    return H_a_General\n",
    "\n",
    "def H_B_General(P_B_General):\n",
    "    H_b_General = np.sum(-P_B_General * np.log2(np.where(P_B_General == 0, 1, P_B_General)))\n",
    "    return H_b_General\n",
    "\n",
    "def H_AB_General(P_AB_General):\n",
    "    P_AB_General = np.where(P_AB_General == 0, 1e-9, P_AB_General)  # replace zero values with 1e-9\n",
    "    H_General = -(P_AB_General * np.log2(P_AB_General)).sum()\n",
    "    return H_General\n",
    "\n",
    "\n",
    "\n",
    "I_AB_General_n2_list_00 = []\n",
    "I_AB_General_n3_list_00 = []\n",
    "\n",
    "P_list = np.linspace(1e-6, 0.1, 101)\n",
    "\n",
    "for P in P_list:\n",
    "    M = 11\n",
    "    compute_M(M)\n",
    "    # n_General = 2\n",
    "    n_General = Compute_G_n(2)\n",
    "    T_General = compute_T_General(n_General, M)\n",
    "\n",
    "    P_D_General_val = P_D_General(n_General, P, 0, l=0, a=0)\n",
    "\n",
    "    P_AB_General_diag_val = P_AB_diag_General(M, n_General)\n",
    "    P_AB_General_diag_val = np.where(P_AB_General_diag_val <= 0, 1e-9, P_AB_General_diag_val)\n",
    "\n",
    "    H_A_General_val = H_A_General(P_AB_General_diag_val)\n",
    "    H_B_General_val = H_B_General(P_AB_General_diag_val)\n",
    "    H_AB_General_val = H_AB_General(P_AB_General_diag_val)\n",
    "\n",
    "    I_AB_General_val = I_AB_General(H_A_General_val, H_B_General_val, H_AB_General_val, P_D_General_val)\n",
    "    I_AB_General_n2_list_00.append(I_AB_General_val)\n",
    "\n",
    "    n_General = Compute_G_n(3)\n",
    "    T_General = compute_T_General(n_General, M)\n",
    "\n",
    "    P_D_General_val = P_D_General(n_General, P, 0, l=0, a=0)\n",
    "\n",
    "    P_AB_General_diag_val = P_AB_diag_General(M, n_General)\n",
    "    P_AB_General_diag_val = np.where(P_AB_General_diag_val <= 0, 1e-9, P_AB_General_diag_val)\n",
    "\n",
    "    H_A_General_val = H_A_General(P_AB_General_diag_val)\n",
    "    H_B_General_val = H_B_General(P_AB_General_diag_val)\n",
    "    H_AB_General_val = H_AB_General(P_AB_General_diag_val)\n",
    "\n",
    "    I_AB_General_val = I_AB_General(H_A_General_val, H_B_General_val, H_AB_General_val, P_D_General_val)\n",
    "    I_AB_General_n3_list_00.append(I_AB_General_val)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(P_list, I_AB_General_n2_list_00, linewidth=3, label='I_AB_General for 2 Photons')\n",
    "plt.plot(P_list, I_AB_General_n3_list_00, linewidth=3, label='I_AB_General for 3 Photons')\n",
    "plt.xlabel('Probability, P')\n",
    "plt.ylabel('Muutal Information, I_AB')\n",
    "plt.title('Mutual Information of BPPM (n=7), PPM (M =11) and \\n General Protocol (n=2,3) vs. Probability 0 \\u2264 P \\u2264  0.1', fontsize='x-large')\n",
    "\n",
    "plt.grid(color='k', linestyle='-', linewidth=0.75)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def P_AB_BPPM(n, P, P_D):\n",
    "#     factorial_n = math.factorial(n)\n",
    "#     matrix = (1/factorial_n) * (1-P_D) * np.diag([1], factorial_n)\n",
    "#     return matrix\n",
    "\n",
    "# def P_AB_BPPM(n, P, P_D):\n",
    "#     factorial_n = math.factorial(n)\n",
    "#     matrix = (1/factorial_n) * (1-P_D) * np.eye(factorial_n)\n",
    "#     return matrix\n",
    "\n",
    "# def P_AB_BPPM(n, P, P_D):\n",
    "#      factorial_n = math.factorial(n)\n",
    "#      diagonal = np.full(factorial_n, factorial_n)\n",
    "#      matrix = np.diag(diagonal) * 1/ (factorial_n) * (1-P_D)\n",
    "#      return matrix\n",
    "\n",
    "# def P_AB_BPPM(n, P, P_D):|\n",
    "#     factorial_n = math.factorial(n)\n",
    "#     matrix = (1/factorial_n) * (1-P_D) * diags([1] * factorial_n) \n",
    "#     return matrix\n",
    "\n",
    "# sum over the elements in rows in the probability matrix P_AB\n",
    "# renormalized in P_AB already\n",
    "\n",
    "# H_A, H_B, H_AB are the same as the trivial case\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def H_A_BPPM(P_AB_BPPM):\n",
    "#      P_A_BPPM = np.sum(P_AB_BPPM, axis=1)\n",
    "#      H_a = np.sum(-P_A_BPPM * np.log2(np.where(P_A_BPPM == 0, 1, P_A_BPPM)))\n",
    "#      return H_a\n",
    "\n",
    "# def H_B_BPPM(P_AB_BPPM):\n",
    "#      P_B_BPPM = np.sum(P_AB_BPPM, axis=0)\n",
    "#      H_b = np.sum(-P_B_BPPM * np.log2(np.where(P_B_BPPM == 0, 1, P_B_BPPM)))\n",
    "#      return H_b\n",
    "\n",
    "# def H_AB_BPPM(P_AB_BPPM):\n",
    "#     P_AB_BPPM = np.where(P_AB_BPPM == 0, 1e-9, P_AB_BPPM)  # replace zero values with 1e-9\n",
    "#     H = -(P_AB_BPPM * np.log2(P_AB_BPPM)).sum()\n",
    "#     return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.eye(factorial_n).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_AB_BPPM_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_AB_BPPM_list = []\n",
    "P_D_list = []\n",
    "P_list = np.linspace(1e-6,0.999999,101)\n",
    "\n",
    "for P in P_list:\n",
    "  n = 5\n",
    "  P_D_val = P_D(n,P, 0,0,0)\n",
    "  P_D_list.append(P_D_val)\n",
    "  # P_AB_BPPM_val = P_AB_BPPM(n, P, P_D_val)\n",
    "  #P_AB_BPPM_val = np.eye(factorial_n) * P_AB_BPPM_val \n",
    "  # P_AB_BPPM_val = np.array(P_AB_BPPM_val) # convert list of lists to numpy array\n",
    "  # P_AB_BPPM_val = np.where(P_AB_BPPM_val <= 0, 1e-15, P_AB_BPPM_val)\n",
    "  # P_AB_BPPM_val = P_AB_BPPM(8, 0, P_D(8,0, 0,0,0))\n",
    "  # H_A_val = H_A_BPPM(P_AB_BPPM_val)\n",
    "  # H_B_val = H_B_BPPM(P_AB_BPPM_val)\n",
    "  # H_AB_val = H_AB_BPPM(P_AB_BPPM_val)\n",
    "  # I_AB_val = I_AB_BPPM(H_A_BPPM_val, H_B_BPPM_val, H_AB_BPPM_val, P_D_val)\n",
    "  # I_AB_list.append(I_AB_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_D_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8\n",
    "factorial_n = math.factorial(n)\n",
    "diagonal = np.full(factorial_n, factorial_n)\n",
    "diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.factorial(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_A_BPPM(P_AB_BPPM(5, 0, P_D(n,0, 0,0,0))),H_A_BPPM(P_AB_BPPM(5, 0, P_D(n,0, 0,0,0))).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_AB_BPPM(5, 0, P_D(5,0, 0,0,0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import diags, csr_matrix\n",
    "\n",
    "# def P_AB_BPPM_sparse(n, P, P_D):\n",
    "#     factorial_n = math.factorial(n)\n",
    "#     data = (1/factorial_n) * (1-P_D) * np.ones(factorial_n)\n",
    "#     offsets = 0\n",
    "#     matrix = diags(data, offsets)\n",
    "#     return matrix\n",
    "\n",
    "# def P_AB_BPPM_sparse(n, P, P_D):\n",
    "#     factorial_n = math.factorial(n)\n",
    "#     matrix = (1/factorial_n) * (1-P_D) * diags([1] * factorial_n)\n",
    "#     return csr_matrix(matrix)\n",
    "\n",
    "# def P_AB_BPPM_sparse_diagonal(n, P, P_D):\n",
    "#     P_AB_BPPM = P_AB_BPPM_sparse(n, P, P_D)\n",
    "#     return P_AB_BPPM.diagonal()\n",
    "\n",
    "def P_AB_BPPM_sparse_diagonal(n, P, P_D):\n",
    "    P_AB_BPPM = P_AB_BPPM_sparse(n, P, P_D)\n",
    "    return P_AB_BPPM.diagonal().flatten()\n",
    "\n",
    "def P_AB_BPPM_sparse(n, P, P_D):\n",
    "    factorial_n = math.factorial(n)\n",
    "    data = (1/factorial_n) * (1-P_D) * np.ones(factorial_n)\n",
    "    offsets = 0\n",
    "    matrix = diags(data, offsets)\n",
    "    return matrix\n",
    "\n",
    "# using taylor method\n",
    "# it deos not with the general method\n",
    "#The only element I want to work out is the diagonal element, and all the off diagonal elements are zero\n",
    "\n",
    "def P_AB_BPPM(n, P, P_D):\n",
    "    factorial_n = math.factorial(n)\n",
    "    matrix = (1/factorial_n) * (1-P_D) * diags([1] * factorial_n) \n",
    "    return matrix\n",
    "\n",
    "def H_A_BPPM(P_AB_BPPM):\n",
    "    P_A_BPPM = np.sum(P_AB_BPPM, axis=1)\n",
    "    H_a = np.sum(-P_A_BPPM.reshape(-1, 1) * np.log2(np.where(P_A_BPPM.reshape(-1, 1) == 0, 1e-9, P_A_BPPM.reshape(-1, 1))))\n",
    "    return H_a\n",
    "\n",
    "def H_B_BPPM(P_AB_BPPM):\n",
    "    P_B_BPPM = np.sum(P_AB_BPPM, axis=0)\n",
    "    H_b = np.sum(-P_B_BPPM.reshape(-1,1) * np.log2(np.where(P_B_BPPM == 0, 1, P_B_BPPM).reshape(-1,1)))\n",
    "    return H_b\n",
    "\n",
    "def H_AB_BPPM(P_AB_BPPM):\n",
    "    P_AB_BPPM = np.where(P_AB_BPPM == 0, 1e-9, P_AB_BPPM)  # replace zero values with 1e-9\n",
    "    H = -(P_AB_BPPM * np.log2(P_AB_BPPM)).sum()\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_AB_BPPM_list = []\n",
    "\n",
    "P_list = np.linspace(1e-6,0.999999,101)\n",
    "\n",
    "for P in P_list:\n",
    "  n = 5\n",
    "  factorial_n = math.factorial(n)\n",
    "  N_n = compute_N(n) \n",
    "  P_D_val = P_D(n,P, 0,0,0) # P_D(n,P_l,P_a, l=0,a=0)\n",
    "  P_AB_BPPM_diagonal = P_AB_BPPM_sparse_diagonal(n, P, P_D_val)\n",
    "  P_AB_BPPM_diagonal = np.where(P_AB_BPPM_diagonal <= 0, 1e-15, P_AB_BPPM_diagonal)\n",
    "  P_A_BPPM = np.sum(P_AB_BPPM_diagonal[:, np.newaxis], axis=0)\n",
    "  P_AB_BPPM_val = diags(P_AB_BPPM_diagonal.reshape(-1))\n",
    "\n",
    "  # P_AB_BPPM_diagonal = P_AB_BPPM_sparse_diagonal(n, P, P_D_val)\n",
    "  # P_AB_BPPM_diagonal = np.where(P_AB_BPPM_diagonal <= 0, 1e-15, P_AB_BPPM_diagonal)\n",
    "  # # P_AB_BPPM_val = csr_matrix(diags(P_AB_BPPM_diagonal.reshape(-1, 1)))\n",
    "  # P_AB_BPPM_val = csr_matrix(diags([P_AB_BPPM_diagonal]))\n",
    "\n",
    "  H_A_BPPM_val = H_A_BPPM(P_AB_BPPM_diagonal)# .reshape(factorial_n, 1))\n",
    "  H_B_BPPM_val = H_B_BPPM(P_AB_BPPM_diagonal) # .reshape(factorial_n, 1))\n",
    "  H_AB_BPPM_val = H_AB_BPPM(P_AB_BPPM_diagonal)# .reshape(factorial_n, 1))\n",
    "  I_AB_BPPM_val = I_AB_BPPM(H_A_BPPM_val, H_B_BPPM_val, H_AB_BPPM_val, P_D_val)\n",
    "  I_AB_BPPM_list.append(I_AB_BPPM_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P_AB_BPPM_diagonal(5, 0, P_D(n,0, 0,0,0)), P_AB_BPPM(5, 0, P_D(n,0, 0,0,0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_AB_BPPM_sparse_diagonal(n, 0, P_D(n,0, 0,0,0)).reshape(factorial_n, 1),  P_AB_BPPM_sparse_diagonal(n, P, P_D_val).reshape(factorial_n, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_A_BPPM(P_AB_BPPM(5, 0, P_D(n,0, 0,0,0))),H_A_BPPM(P_AB_BPPM(5, 0, P_D(n,0, 0,0,0))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(P_list, I_AB_BPPM_list, label='I_AB_BPPM renormalized', linewidth=3, alpha=1)\n",
    "\n",
    "\n",
    "# Add axis labels and a title\n",
    "plt.xlabel('Probability, P')\n",
    "plt.ylabel('Muutal Information, I_AB')\n",
    "plt.title('Mutual Information of BPPM (n = 5), PPM (M = 5) and  \\n General Protocol (n =2, 3) vs. Probability 0 \\u2264 P \\u2264 0.1', fontsize='x-large')\n",
    "\n",
    "plt.grid(color='k', linestyle='-', linewidth=0.75)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello everyone, I have a matrix as following matrix, it will be getting larger and larger for a large number of n.\n",
    "Actually, it is a diagonal matrix, what I want is only to compute the diagonal elements and the off diagonal elements are all zero. Is there any method I can make it work? I am not sure should I use sparse matrix representation instead of a dense matrix. Although this can significantly reduce memory usage and computational time for larger values of n, but I cannot reshape it back to the square matrix form as n! x n!\n",
    "\n",
    "I hope someone can shed some light! \n",
    "\n",
    "```py\n",
    "def P_AB(n, P, P_D):\n",
    "    factorial_n = math.factorial(n)\n",
    "    matrix = (1/factorial_n) * (1-P_D) * np.eye(factorial_n)\n",
    "    return matrix\n",
    "\n",
    "def H_A(P_AB):\n",
    "     P_A = np.sum(P_AB, axis=1)\n",
    "     H_a = np.sum(-P_A * np.log2(np.where(P_A == 0, 1, P_A)))\n",
    "     return H_a\n",
    "\n",
    "def H_B(P_AB):\n",
    "     P_B = np.sum(P_AB, axis=0)\n",
    "     H_b = np.sum(-P_B * np.log2(np.where(P_B == 0, 1, P_B)))\n",
    "     return H_b\n",
    "\n",
    "def H_AB(P_AB):\n",
    "    P_AB = np.where(P_AB == 0, 1e-9, P_AB)  # replace zero values with 1e-9\n",
    "    H = -(P_AB* np.log2(P_AB)).sum()\n",
    "    return H\n",
    "\n",
    "def I_AB(H_A, H_B, H_AB, P_D):\n",
    "    if np.isnan(H_AB):\n",
    "        return 0\n",
    "    else:\n",
    "        return ((H_A + H_B - H_AB))*(1-P_D)\n",
    "´´´\n",
    "Thank you very much!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " constant energy per information bit\n",
    "\n",
    " keep number of photon / log2(K) \n",
    "\n",
    "\n",
    "For BPPM, n = 5, M = 26, K = 5! = 120\n",
    "\n",
    "log_2(120) = 6.9\n",
    "\n",
    "n / log_2(K) = 5/ 6.9 = 0.7\n",
    "\n",
    "\n",
    "For PPM, n = 1, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functools import lru_cache\n",
    "\n",
    "# comb_cache = {}\n",
    "# comb_n_cache = {}\n",
    "# comb_n_M_minus_n_cache = {}\n",
    "\n",
    "# #we need combination to calculate Loss_Disitribution, Add_Distribution, P_err\n",
    "# # define a separate function for computing the sequence of terms used in N\n",
    "\n",
    "# @lru_cache(maxsize=None)\n",
    "# def compute_N(n):\n",
    "#   def agen(): # generator of terms\n",
    "#       aset, sset, k = set(), set(), 0\n",
    "#       while True:\n",
    "#           k += 1\n",
    "#           while any(k+an in sset for an in aset): k += 1\n",
    "#           yield k; sset.update(k+an for an in aset); aset.add(k)\n",
    "#   a = list(islice(agen(), 100))\n",
    "#   photon = list(map(lambda v: v-1, a))\n",
    "#   compute_N= [sum(photon[:i]) for i in range(1,len(photon)+1)]\n",
    "#   return compute_N[n]\n",
    "\n",
    "# def precompute_combinations(max_n):\n",
    "#     for n in range(max_n+1):\n",
    "#         for r in range(n+1):\n",
    "#             comb = math.factorial(n) // (math.factorial(n-r) * math.factorial(r))\n",
    "#             comb_cache[(n, r)] = comb\n",
    "\n",
    "# def combination(n, r):\n",
    "#     return comb_cache.get((n, r), 0)\n",
    "    \n",
    "# # We need LossDisitribution, AddDistribution, Perr to calculate PSuccess0, PSuccess1, PSuccess2 and so on\n",
    "# # define a separate function for computing the loss distribution\n",
    "\n",
    "# def Loss_Distribute(n, P_l, l):\n",
    "#     comb_n = combination(n, l)\n",
    "#     return comb_n * (P_l)**l * (1 - P_l)**(n - l)\n",
    "\n",
    "# def Add_Distribute(n, P_a, a, N_n):\n",
    "#     M_minus_n = N_n - n\n",
    "#     comb_Nn_Mn = combination(N_n + M_minus_n, a)\n",
    "#     return comb_Nn_Mn * (P_a)**a * (1 - P_a)**(M_minus_n - a)\n",
    "\n",
    "# # define a separate function for computing the probability of error\n",
    "# def P_err_BPPM(n, P_l, P_a,l,a, N_n):\n",
    "#   return Loss_Distribute(n,P_l,l) * Add_Distribute(n,P_a, a, N_n)\n",
    "#   #return combination(n,l) * (P_l)**l*(1-P_l)**(n-l) * combination(N-n,a) * (P_a)**a*(1-P_a)**(N-n-a) \n",
    "\n",
    "# # We put these into P_D for re-normalization, These are the probability of error we can correct\n",
    "# # define separate functions for computing the probability of success\n",
    "# def P_Success0(n,P_l,P_a,l,a, N_n):\n",
    "#   return P_err_BPPM(n,P_l, P_a,0,0,N_n)\n",
    "\n",
    "# def P_Success1(n, P_l, P_a, l, a, N_n):\n",
    "#     P0 = P_Success0(n, P_l, P_a, l, a, N_n)\n",
    "#     P1 = P_err_BPPM(n, P_l, P_a, 0, 1, N_n) + P_err_BPPM(n, P_l, P_a, 1, 0, N_n)\n",
    "#     return P0 + P1\n",
    "\n",
    "# def P_Success2(n,P_l,P_a,l,a, N_n):\n",
    "#     P1 = P_Success1(n, P_l, P_a)\n",
    "#     P2 = P_err_BPPM(n, P_l, P_a, 1, 1, N_n) + P_err_BPPM(n, P_l, P_a, 2, 0, N_n) + P_err_BPPM(n, P_l, P_a, 0, 2, N_n)\n",
    "#     return P1 + P2\n",
    "\n",
    "# def P_Success3(n,P_l,P_a,l,a, N_n):\n",
    "#     P2 = P_err_BPPM(n, P_l, P_a, 1, 1, N_n) + P_err_BPPM(n, P_l, P_a, 2, 0, N_n) + P_err_BPPM(n, P_l, P_a, 0, 2, N_n)\n",
    "#     P3 = P_err_BPPM(n, P_l, P_a,1,2, N_n) + P_err_BPPM(n, P_l, P_a, 2,1, N_n) + P_err_BPPM(n, P_l, P_a,3,0, N_n) + P_err_BPPM(n, P_l, P_a,0,3, N_n)\n",
    "#     return P2 + P3\n",
    "\n",
    "# def P_D(n,P_l,P_a,l,a, N_n):\n",
    "# # we only consider at most 1 error, i.e. P_0 + P_1\n",
    "#   return 1 - P_Success1(n,P_l,P_a,l,a, N_n)\n",
    "\n",
    "# # sum over the elements in rows in the probability matrix P_AB\n",
    "# # renormalized in P_AB already\n",
    "# def P_A_BPPM(P_AB_BPPM, P_D):\n",
    "#     if P_D == 1:\n",
    "#         return [1 for row in P_AB_BPPM]\n",
    "#     else:\n",
    "#         return [1/(1-P_D) * sum(row) for row in P_AB_BPPM] \n",
    "# # sum over the elements in columns in the probability matrix P_AB\n",
    "# # renormalized in P_AB already\n",
    "\n",
    "# def P_B_BPPM(P_AB_BPPM, P_D):\n",
    "#     if P_D == 1:\n",
    "#         return [1 for col in zip(*P_AB_BPPM)]\n",
    "#     else:\n",
    "#         return [1/(1-P_D) * sum(col) for col in zip(*P_AB_BPPM)]\n",
    "# # # calculate the trace of the probability matrix P_AB\n",
    "\n",
    "# def I_AB_BPPM(H_A_BPPM, H_B_BPPM, H_AB_BPPM, P_D):\n",
    "#     if np.isnan(H_AB_BPPM):\n",
    "#         return 0\n",
    "#     else:\n",
    "#         return ((H_A_BPPM + H_B_BPPM - H_AB_BPPM))*(1-P_D)\n",
    "        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# def P_AB_BPPM(n, P_D):\n",
    "#     factorial_n = round(math.gamma(n + 1))\n",
    "#     diag_data = (1/factorial_n) * (1-P_D) * np.ones(factorial_n)\n",
    "#     matrix = sps.dia_matrix((diag_data, 0), shape=(factorial_n, factorial_n))\n",
    "#     return matrix\n",
    "\n",
    "# def entropy(P):\n",
    "#     P_non_zero = np.where(P == 0, 1, P)\n",
    "#     H = -np.sum(P * np.log2(P_non_zero))\n",
    "#     return H\n",
    "\n",
    "# def H_A_BPPM(P_AB_BPPM):\n",
    "#     P_A_BPPM = P_AB_BPPM.diagonal()\n",
    "#     return np.sum(-P_A_BPPM * np.log2(np.where(P_A_BPPM == 0, 1, P_A_BPPM)))\n",
    "\n",
    "# def H_B_BPPM(P_AB_BPPM):\n",
    "#     P_B_BPPM = P_AB_BPPM.diagonal()\n",
    "#     return np.sum(-P_B_BPPM * np.log2(np.where(P_B_BPPM == 0, 1, P_B_BPPM)))\n",
    "\n",
    "# def H_AB_BPPM(P_AB_BPPM):\n",
    "#     P_AB_BPPM = P_AB_BPPM.diagonal()\n",
    "#     P_AB_BPPM = np.where(P_AB_BPPM == 0, 1e-9, P_AB_BPPM)  # replace zero values with 1e-9\n",
    "#     return -(P_AB_BPPM * np.log2(P_AB_BPPM)).sum()\n",
    "\n",
    "\n",
    "# # Precompute the combinations\n",
    "# precompute_combinations(max_n=10)  # Adjust max_n as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_AB_BPPM(n, P_D):\n",
    "    factorial_n = math.factorial(n)\n",
    "    diag_data = (1/factorial_n) * (1-P_D) * np.ones(factorial_n)\n",
    "    matrix = sps.dia_matrix((diag_data, 0), shape=(factorial_n, factorial_n))\n",
    "    return matrix\n",
    "\n",
    "def H_A_BPPM(P_AB_BPPM):\n",
    "    P_A_BPPM = P_AB_BPPM.diagonal()\n",
    "    H_a = np.sum(-P_A_BPPM * np.log2(np.where(P_A_BPPM == 0, 1, P_A_BPPM)))\n",
    "    return H_a\n",
    "\n",
    "def H_B_BPPM(P_AB_BPPM):\n",
    "    P_B_BPPM = P_AB_BPPM.diagonal()\n",
    "    H_b = np.sum(-P_B_BPPM * np.log2(np.where(P_B_BPPM == 0, 1, P_B_BPPM)))\n",
    "    return H_b\n",
    "\n",
    "def H_AB_BPPM(P_AB_BPPM):\n",
    "    P_AB_BPPM = P_AB_BPPM.diagonal()\n",
    "    P_AB_BPPM = np.where(P_AB_BPPM == 0, 1e-9, P_AB_BPPM)  # replace zero values with 1e-9\n",
    "    H = -(P_AB_BPPM * np.log2(P_AB_BPPM)).sum()\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_cache = {}\n",
    "#we need combination to calculate Loss_Disitribution, Add_Distribution, P_err\n",
    "# define a separate function for computing the sequence of terms used in N\n",
    "# def combination(n, r):\n",
    "#     # if r > n:\n",
    "#     #     return 0\n",
    "#     # else:\n",
    "#     return math.factorial((int(n))) / (math.factorial((int(n-r))) * math.factorial((int(r))))\n",
    "\n",
    "\n",
    "def combination(n, r):\n",
    "    if (n, r) in comb_cache:\n",
    "        return comb_cache[(n, r)]\n",
    "    else:\n",
    "        comb = math.factorial(n) // (math.factorial(n-r) * math.factorial(r))\n",
    "        comb_cache[(n, r)] = comb\n",
    "        return comb\n",
    "    \n",
    "@lru_cache(maxsize=None)\n",
    "def compute_N(n):\n",
    "  def agen(): # generator of terms\n",
    "      aset, sset, k = set(), set(), 0\n",
    "      while True:\n",
    "          k += 1\n",
    "          while any(k+an in sset for an in aset): k += 1\n",
    "          yield k; sset.update(k+an for an in aset); aset.add(k)\n",
    "  a = list(islice(agen(), 100))\n",
    "  photon = list(map(lambda v: v-1, a))\n",
    "  compute_N= [sum(photon[:i]) for i in range(1,len(photon)+1)]\n",
    "  return compute_N[n]\n",
    "\n",
    "# We need LossDisitribution, AddDistribution, Perr to calculate PSuccess0, PSuccess1, PSuccess2 and so on\n",
    "# define a separate function for computing the loss distribution\n",
    "comb_n_cache = {}\n",
    "\n",
    "# def Loss_Distribute(n, P_l, l):\n",
    "    # # if P_l == 0:\n",
    "    # #     return 1\n",
    "    # # else:\n",
    "    #   return combination(n, l) * (P_l)**l * (1 - P_l)**(n - l)\n",
    "\n",
    "def Loss_Distribute(n, P_l, l):\n",
    "    if (n, l) in comb_n_cache:\n",
    "        comb_n = comb_n_cache[(n, l)]\n",
    "    else:\n",
    "        comb_n = combination(n, l)\n",
    "        comb_n_cache[(n, l)] = comb_n\n",
    "\n",
    "    return comb_n * (P_l)**l * (1 - P_l)**(n - l)\n",
    "\n",
    "# def Add_Distribute(n, P_a, a):\n",
    "#     N_n = compute_N(n)\n",
    "#     # if P_a == 0:\n",
    "#     #     return 1\n",
    "#     # else:\n",
    "#     return combination(N_n - n, a) * (P_a)**a * (1 - P_a)**(N_n - n - a)\n",
    "\n",
    "comb_n_M_minus_n_cache = {}\n",
    "def Add_Distribute(n, P_a, a):\n",
    "    N_n = compute_N(n)\n",
    "    M_minus_n = compute_N(n) - N_n\n",
    "    if (N_n, M_minus_n, a) in comb_n_M_minus_n_cache:\n",
    "        comb_Nn_Mn = comb_n_M_minus_n_cache[(N_n, M_minus_n, a)]\n",
    "    else:\n",
    "        comb_Nn_Mn = combination(N_n + M_minus_n, a)\n",
    "        comb_n_M_minus_n_cache[(N_n, M_minus_n, a)] = comb_Nn_Mn\n",
    "\n",
    "    return comb_Nn_Mn * (P_a)**a * (1 - P_a)**(M_minus_n - a)\n",
    "\n",
    "# define a separate function for computing the probability of error\n",
    "def P_err(n, P_l, P_a,l,a):\n",
    "  return Loss_Distribute(n,P_l,l) * Add_Distribute(n,P_a, a)\n",
    "  #return combination(n,l) * (P_l)**l*(1-P_l)**(n-l) * combination(N-n,a) * (P_a)**a*(1-P_a)**(N-n-a) \n",
    "\n",
    "# We put these into P_D for re-normalization, These are the probability of error we can correct\n",
    "# define separate functions for computing the probability of success\n",
    "def P_Success0(n,P_l,P_a,l,a):\n",
    "  return P_err(n,P_l, P_a,0,0)\n",
    "\n",
    "def P_Success1(n,P_l,P_a,l,a):\n",
    "  P0 = P_Success0(n, P_l, P_a,l,a)\n",
    "  P1 = P_err(n, P_l, P_a, l=0, a=1) + P_err(n, P_l, P_a, l=1, a=0)\n",
    "  return P0 + P1\n",
    "\n",
    "def P_Success2(n,P_l,P_a,l,a):\n",
    "  P1 = P_Success1(n, P_l, P_a)\n",
    "  P2 = P_err(n, P_l, P_a, l=1, a=1) + P_err(n, P_l, P_a, l=2, a=0) + P_err(n, P_l, P_a, l=0, a=2)\n",
    "  return P1 + P2\n",
    "\n",
    "def P_Success3(n,P_l,P_a,l,a):\n",
    "  P2 = P_err(n, P_l, P_a, l=1, a=1) + P_err(n, P_l, P_a, l=2, a=0) + P_err(n, P_l, P_a, l=0, a=2)\n",
    "  P3 = P_err(n, P_l, P_a,1,2) + P_err(n, P_l, P_a, 2,1) + P_err(n, P_l, P_a,3,0) + P_err(n, P_l, P_a,0,3)\n",
    "  return P2 + P3\n",
    "\n",
    "def P_D(n,P_l,P_a,l,a):\n",
    "# we only consider at most 1 error, i.e. P_0 + P_1\n",
    "  return 1 - P_Success1(n,P_l,P_a,l,a)\n",
    "\n",
    "# sum over the elements in rows in the probability matrix P_AB\n",
    "# renormalized in P_AB already\n",
    "def P_A_BPPM(P_AB_BPPM, P_D):\n",
    "    if P_D == 1:\n",
    "        return [1 for row in P_AB_BPPM]\n",
    "    else:\n",
    "        return [1/(1-P_D) * sum(row) for row in P_AB_BPPM] \n",
    "# sum over the elements in columns in the probability matrix P_AB\n",
    "# renormalized in P_AB already\n",
    "def P_B_BPPM(P_AB_BPPM, P_D):\n",
    "    if P_D == 1:\n",
    "        return [1 for col in zip(*P_AB_BPPM)]\n",
    "    else:\n",
    "        return [1/(1-P_D) * sum(col) for col in zip(*P_AB_BPPM)]\n",
    "# # calculate the trace of the probability matrix P_AB\n",
    "# def trace_P_AB(P_AB):\n",
    "#     return sum([P_AB[i][i] for i in range(len(P_AB))])\n",
    "\n",
    "# H_A, H_B, H_AB are the same as the trivial case\n",
    "\n",
    "# def I_AB(H_A, H_B, H_AB, P_D):\n",
    "#   return ((H_A + H_B - H_AB))*(1-P_D)\n",
    "\n",
    "def I_AB_BPPM(H_A_BPPM, H_B_BPPM, H_AB_BPPM, P_D):\n",
    "    if np.isnan(H_AB_BPPM):\n",
    "        return 0\n",
    "    else:\n",
    "        return ((H_A_BPPM + H_B_BPPM - H_AB_BPPM))*(1-P_D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "I_AB_BPPM_list_11 = []\n",
    "H_AB_BPPM_list_11 = []\n",
    "P_AB_BPPM_list_11 = []\n",
    "Normalized_I_AB_BPPM_list_11 = []\n",
    "\n",
    "P_list = np.linspace(1e-6, 0.1, 101)\n",
    "\n",
    "for P in P_list:\n",
    "    n = 5\n",
    "    N_n = compute_N(n)\n",
    "    P_D_val = P_D(n, P, 0, 0, 0)\n",
    "\n",
    "    P_AB_BPPM_val = P_AB_BPPM(n, P_D_val)\n",
    "    P_AB_BPPM_list_11.append(P_AB_BPPM_val)\n",
    "\n",
    "    H_A_BPPM_val = H_A_BPPM(P_AB_BPPM_val)\n",
    "    H_B_BPPM_val = H_B_BPPM(P_AB_BPPM_val)\n",
    "    H_AB_BPPM_val = H_AB_BPPM(P_AB_BPPM_val)\n",
    "\n",
    "    H_AB_BPPM_list_11.append(H_AB_BPPM_val)\n",
    "\n",
    "    I_AB_BPPM_val = I_AB_BPPM(H_A_BPPM_val, H_B_BPPM_val, H_AB_BPPM_val, P_D_val)\n",
    "    I_AB_BPPM_list_11.append(I_AB_BPPM_val)\n",
    "    # Normalized_I_AB_BPPM_val = I_AB_BPPM(H_A_BPPM_val, H_B_BPPM_val, H_AB_BPPM_val, P_D_val) / I_AB_BPPM(H_A_BPPM_val, H_B_BPPM_val, H_AB_BPPM_val, 0)\n",
    "    # Normalized_I_AB_BPPM_list_11.append(Normalized_I_AB_BPPM_val)\n",
    "# Plot the results\n",
    "plt.plot(P_list, H_AB_BPPM_list_11, label='n=11', linewidth=3)\n",
    "plt.xlabel('P')\n",
    "plt.ylabel('I_AB_BPPM')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(H_AB_BPPM(P_AB_BPPM(5,P_D(5, 0, 0, 0, 0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(I_AB_BPPM(H_A_BPPM(P_AB_BPPM(5,P_D(5, 0, 0, 0, 0))), H_A_BPPM(P_AB_BPPM(5,P_D(5, 0, 0, 0, 0))), H_AB_BPPM(P_AB_BPPM(5,P_D(5, 0, 0, 0, 0))), P_D(5, 0, 0, 0, 0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
